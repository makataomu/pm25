{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def determine_max_lags(train_df, min_lags=10, max_fraction=0.5, max_limit=400):\n",
    "    \"\"\" Determines the maximum number of lags based on train set size. \"\"\"\n",
    "    max_lags = min(int(len(train_df) * max_fraction), max_limit)\n",
    "    return max(max_lags, min_lags)  # Ensure at least min_lags\n",
    "\n",
    "def determine_dynamic_max_lags(train_df, min_lags=20, max_fraction=0.5, max_limit=400):\n",
    "    \"\"\"\n",
    "    Dynamically determines a range of max_lags values based on train size.\n",
    "    Returns a list of `max_lags` values to be tested.\n",
    "    \"\"\"\n",
    "    base_max_lags = min(int(len(train_df) * max_fraction), max_limit)  # Base max lags\n",
    "    \n",
    "    # Create diverse lag options (quarter, half, full, and extended)\n",
    "    max_lags_list = [\n",
    "        # max(min_lags, base_max_lags // 6),   # Small max_lags\n",
    "        max(min_lags, base_max_lags // 4),   # Small max_lags\n",
    "        max(min_lags, base_max_lags // 2),   # Medium max_lags\n",
    "        base_max_lags,                      # Full max_lags\n",
    "    ]\n",
    "    \n",
    "    # Remove duplicates and ensure sorted order\n",
    "    max_lags_list = sorted(set(max_lags_list))\n",
    "\n",
    "    return max_lags_list\n",
    "\n",
    "\n",
    "def generate_lagged_features(train_df, target_col, max_lags):\n",
    "    \"\"\"Generates lagged features while keeping the `ds` column.\"\"\"\n",
    "    # lagged_features = pd.concat([\n",
    "        # train_df[[target_col, \"ds\"]].assign(**{f'lag_{lag}': train_df[target_col].shift(lag)}) for lag in range(1, max_lags + 1)\n",
    "    # ], axis=1)\n",
    "    # train_df.set_index(\"ds\", inplace=True)\n",
    "    lagged_features = pd.concat([\n",
    "        train_df[target_col].shift(lag).rename(f'lag_{lag}') for lag in range(1, max_lags + 1)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Drop missing values (due to shifting) and reset index\n",
    "    lagged_features = lagged_features.dropna().reset_index(drop=True)\n",
    "    \n",
    "    return lagged_features\n",
    "\n",
    "\n",
    "def select_important_lags(train_df, target_col, max_lags, model=RandomForestRegressor(), num_of_lags=10):\n",
    "    \"\"\" Selects the most important lags based on feature importance analysis. \"\"\"\n",
    "    lagged_features = generate_lagged_features(train_df, target_col, max_lags)\n",
    "    y = train_df[target_col][max_lags:]  # Align target values\n",
    "    \n",
    "    if lagged_features.shape[0] != len(y):  # Avoid mismatched sizes\n",
    "        lagged_features = lagged_features.iloc[:len(y)]\n",
    "    \n",
    "    model.fit(lagged_features, y)\n",
    "    feature_importances = model.feature_importances_\n",
    "    important_lags = [i + 1 for i in np.argsort(feature_importances)[-num_of_lags:]]  # Select top lags\n",
    "    \n",
    "    return sorted(important_lags)\n",
    "\n",
    "def select_important_lags_extended(train_df, target_col, max_lags, model=RandomForestRegressor(), num_of_lags_list=[5, 10, 15]):\n",
    "    \"\"\" Selects the most important lags based on feature importance analysis for multiple numbers of lags.\"\"\"\n",
    "    lagged_features = generate_lagged_features(train_df, target_col, max_lags)\n",
    "\n",
    "    y = train_df[target_col][max_lags:]\n",
    "    if lagged_features.shape[0] != len(y):  # Avoid mismatched sizes\n",
    "        lagged_features = lagged_features.iloc[:len(y)]\n",
    "    \n",
    "    model.fit(lagged_features, y)\n",
    "    feature_importances = model.feature_importances_\n",
    "    \n",
    "    important_lags_lists = {}\n",
    "    for num_of_lags in num_of_lags_list:\n",
    "        important_lags = [i + 1 for i in np.argsort(feature_importances)[-num_of_lags:]]  # Select top lags\n",
    "        name = f\"lags_{max_lags}_features_{num_of_lags}\"  # Generate a meaningful name\n",
    "        important_lags_lists[name] = [int(x) for x in sorted(important_lags)]  # Store with name\n",
    "    \n",
    "    return important_lags_lists\n",
    "\n",
    "def get_optimal_lags(train_df, target_col, model=RandomForestRegressor(), ratios=[0.33, 0.66, 1]):\n",
    "    \"\"\" Selects the most important lags dynamically based on train size. \"\"\"\n",
    "    max_lags_list = determine_dynamic_max_lags(train_df)  # Get dynamic max_lags\n",
    "    results = {}\n",
    "\n",
    "    for max_lags in max_lags_list:\n",
    "        num_of_lags_list = [int(max_lags * ratio) for ratio in ratios]  # Various % of max_lags\n",
    "\n",
    "        # Select important lags and store them with meaningful names\n",
    "        selected_lags = select_important_lags_extended(train_df, target_col, max_lags, model, num_of_lags_list)\n",
    "        \n",
    "        # Merge into results dictionary\n",
    "        results.update(selected_lags)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.target_transforms import (\n",
    "    Differences, AutoDifferences, AutoSeasonalDifferences, AutoSeasonalityAndDifferences,\n",
    "    LocalStandardScaler, LocalMinMaxScaler, LocalBoxCox\n",
    ")\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, SGDRegressor\n",
    "from itertools import combinations, chain\n",
    "import pickle\n",
    "\n",
    "# Dummy dataset function\n",
    "def create_dummy_data():\n",
    "    \"\"\"Generates a dummy time series dataset with three years of daily data.\"\"\"\n",
    "    dates = pd.date_range(start=\"2020-01-01\", end=\"2022-12-31\", freq='D')\n",
    "    values = np.sin(np.linspace(0, 50, len(dates))) + np.random.normal(0, 0.1, len(dates))  # Pattern with noise\n",
    "    df = pd.DataFrame({\"ds\": dates, \"y\": values})\n",
    "    return df\n",
    "\n",
    "def mape_met(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-9))) * 100\n",
    "\n",
    "# Function to dynamically determine seasonal and differencing parameters\n",
    "def get_dynamic_transforms(train_df):\n",
    "    max_diffs = min(len(train_df) // 2, 380)  # Avoid excessive differencing\n",
    "    season_length = min(len(train_df) // 3, 365)  # Estimate reasonable seasonality\n",
    "\n",
    "    target_transforms = [\n",
    "        AutoDifferences(max_diffs=max_diffs), \n",
    "        AutoSeasonalDifferences(season_length=season_length, max_diffs=max_diffs), \n",
    "        AutoSeasonalityAndDifferences(max_season_length=season_length, max_diffs=max_diffs),\n",
    "        LocalStandardScaler(), \n",
    "        LocalMinMaxScaler(), \n",
    "        LocalBoxCox()\n",
    "    ]\n",
    "    return target_transforms\n",
    "\n",
    "# Function to dynamically determine max lags\n",
    "def determine_max_lags(train_df, min_lags=20, max_fraction=0.5, max_limit=400):\n",
    "    \"\"\" Determines the maximum number of lags based on train set size. \"\"\"\n",
    "    max_lags = min(int(len(train_df) * max_fraction), max_limit)\n",
    "    return max(max_lags, min_lags)\n",
    "\n",
    "\n",
    "# Function to validate transform combinations\n",
    "def filter_conflicting_transforms(transform_combination):\n",
    "    conflicting_transforms = {Differences, AutoDifferences, AutoSeasonalDifferences, AutoSeasonalityAndDifferences}\n",
    "    scaler_transforms = {LocalStandardScaler, LocalMinMaxScaler, LocalBoxCox}\n",
    "    \n",
    "    if sum(1 for t in transform_combination if type(t) in conflicting_transforms) > 1:\n",
    "        return False\n",
    "    if sum(1 for t in transform_combination if type(t) in scaler_transforms) > 1:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Model Evaluation Pipeline\n",
    "def evaluate_models(train_df, test_df, models, target_transforms, lag_transforms_options, optimal_lags_list, date_features=['dayofweek', 'month']):\n",
    "    \"\"\"\n",
    "    Evaluates multiple models with different transformations, lag selections, and lag transformations.\n",
    "    Now accepts precomputed `optimal_lags_list` instead of calculating inside.\n",
    "    \"\"\"\n",
    "    best_model = None\n",
    "    best_error = float('inf')\n",
    "    best_transforms = None\n",
    "    best_lags = None\n",
    "    best_lag_transforms = None\n",
    "    results = {}\n",
    "\n",
    "    # Validate transform combinations\n",
    "    valid_transform_combinations = list(chain(combinations(target_transforms, 1), combinations(target_transforms, 2)))\n",
    "    valid_transform_combinations = [tc for tc in valid_transform_combinations if filter_conflicting_transforms(tc)]\n",
    "\n",
    "    total_fits = len(models) * len(valid_transform_combinations) * len(optimal_lags_list) * len(lag_transforms_options)\n",
    "    print(f\"Total model fits to run: {total_fits}\")\n",
    "\n",
    "    fit_num = 0\n",
    "    for lag_name, optimal_lags in optimal_lags_list.items():  # Now uses precomputed lags\n",
    "        for transform_combination in valid_transform_combinations:\n",
    "            for lag_transforms in lag_transforms_options:\n",
    "                for model_name, model in models.items():\n",
    "                    print(f\"{fit_num}/{total_fits} Training {model_name} with transforms {transform_combination}, lags {optimal_lags}, and lag_transforms {lag_transforms}...\")\n",
    "\n",
    "                    try:\n",
    "                        fcst = MLForecast(\n",
    "                            models=[model],\n",
    "                            freq='D',\n",
    "                            lags=optimal_lags,\n",
    "                            target_transforms=list(transform_combination),\n",
    "                            date_features=date_features,\n",
    "                            num_threads=1,\n",
    "                            lag_transforms=lag_transforms,\n",
    "                        )\n",
    "                        \n",
    "                        # Fit the model\n",
    "                        fcst.fit(train_df)\n",
    "                        \n",
    "                        # Predict\n",
    "                        predictions = fcst.predict(h=len(test_df['y']))\n",
    "                        \n",
    "                        # Store results\n",
    "                        # Merge predictions back to maintain the `ds` column\n",
    "                        # test_df = test_df.copy()\n",
    "                        # test_df = test_df.iloc[:len(predictions)].copy()  # Ensure same length\n",
    "                        # test_df['forecast'] = predictions[model_name]\n",
    "                        # error = np.mean(np.abs((test_df['y'].values - test_df['forecast'].values) / test_df['y'].values)) * 100\n",
    "                        error = mape_met(test_df['y'].values, predictions[model_name])\n",
    "                        # print(stringify_transform(list(transform_combination)))\n",
    "                        results[(model_name, stringify_transform(list(transform_combination)), tuple(optimal_lags), clean_lag_transforms(lag_transforms), lag_name)] = error\n",
    "                        print(f\"{model_name} MAPE: {error:.2f}% with transforms {transform_combination}, lags {optimal_lags}, and lag_transforms {lag_transforms}\")\n",
    "                        \n",
    "                        if error < best_error:\n",
    "                            best_error = error\n",
    "                            best_model = model_name\n",
    "                            best_transforms = transform_combination\n",
    "                            best_lags = optimal_lags\n",
    "                            best_lag_transforms = lag_transforms\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"Skipping combination due to error: {e}\")\n",
    "                    fit_num += 1\n",
    "    \n",
    "    print(f\"Best Model: {best_model} with MAPE {best_error:.2f}% using transforms {best_transforms}, lags {best_lags}, and lag_transforms {best_lag_transforms}\")\n",
    "    return results\n",
    "\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def stringify_transform(transforms):\n",
    "    \"\"\"\n",
    "    Convert transformation(s) into a standardized string format including parameters.\n",
    "    \n",
    "    - Handles both **single** transformations and **lists** of transformations.\n",
    "    - Extracts parameters **only if `scaler_` exists**, otherwise just takes the class name.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(transforms, list):  # If it's a single transformation, wrap it in a list\n",
    "        transforms = [transforms]\n",
    "\n",
    "    transform_strings = []\n",
    "    \n",
    "    for transform in transforms:\n",
    "        class_name = transform.__class__.__name__  # Get the class name\n",
    "        \n",
    "        # Check if the transform has a `scaler_` attribute\n",
    "        if hasattr(transform, 'scaler_'):\n",
    "            actual_transform = transform.scaler_\n",
    "            \n",
    "            # Extract all attributes dynamically\n",
    "            attr_strings = []\n",
    "            for attr in dir(actual_transform):\n",
    "                if (not attr.startswith(\"_\")) \\\n",
    "                    and (not callable(getattr(actual_transform, attr, None))) \\\n",
    "                    and (attr not in ['tails_', 'diffs_']) \\\n",
    "                :\n",
    "                    attr_value = getattr(actual_transform, attr, None)\n",
    "                    attr_strings.append(f\"{attr}={attr_value}\")\n",
    "            \n",
    "            # Format class name + parameters\n",
    "            attr_str = \", \".join(attr_strings) if attr_strings else \"NoParams\"\n",
    "            transform_strings.append(f\"{class_name}({attr_str})\")\n",
    "        \n",
    "        else:\n",
    "            # If no `scaler_`, just store the class name\n",
    "            transform_strings.append(class_name + '()')\n",
    "    \n",
    "    return \" | \".join(transform_strings)  # Join multiple transformations with \" | \"\n",
    "\n",
    "\n",
    "def parse_transform(transform_str):\n",
    "    \"\"\"\n",
    "    Convert string representation back into a list of transformation objects.\n",
    "    - Handles **single** and **multiple** transformations.\n",
    "    - Extracts parameters dynamically if present.\n",
    "    \"\"\"\n",
    "    \n",
    "    transform_list = transform_str.split(\" | \")  # Split multiple transforms\n",
    "    parsed_transforms = []\n",
    "    \n",
    "    for transform_item in transform_list:\n",
    "        if \"(\" in transform_item:  # If parameters exist\n",
    "            class_name, params_str = transform_item.split(\"(\", 1)\n",
    "            params_str = params_str.rstrip(\")\")\n",
    "            \n",
    "            # Extract parameters into a dictionary\n",
    "            params = {}\n",
    "            if params_str != \"NoParams\":\n",
    "                for param in params_str.split(\", \"):\n",
    "                    key, value = param.split(\"=\")\n",
    "                    try:\n",
    "                        params[key] = eval(value)  # Convert to appropriate type (int, float, etc.)\n",
    "                    except:\n",
    "                        params[key] = value  # Keep as string if eval fails\n",
    "            \n",
    "            # Dynamically create the object\n",
    "            if class_name in globals():\n",
    "                parsed_transforms.append(globals()[class_name](**params))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown transform class: {class_name}\")\n",
    "\n",
    "        else:\n",
    "            # No parameters, just instantiate by class name\n",
    "            if transform_item in globals():\n",
    "                parsed_transforms.append(globals()[transform_item]())\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown transform class: {transform_item}\")\n",
    "    \n",
    "    return parsed_transforms if len(parsed_transforms) > 1 else parsed_transforms[0]\n",
    "\n",
    "\n",
    "\n",
    "def clean_lag_transforms(lag_transforms):\n",
    "    \"\"\"Converts lag transforms dictionary into a readable string identifier.\"\"\"\n",
    "    if not lag_transforms:\n",
    "        return \"No_Lag_Transforms\"\n",
    "    \n",
    "    transform_names = []\n",
    "    for lag, funcs in lag_transforms.items():\n",
    "        func_names = \"_\".join(func.__name__ for func in funcs)\n",
    "        transform_names.append(f\"Lag{lag}:{func_names}\")\n",
    "    \n",
    "    return \"|\".join(transform_names)  # Join using \"|\" for readability\n",
    "\n",
    "\n",
    "def save_results(results, filename=\"forecast_results.json\"):\n",
    "    \"\"\"Serializes model results into JSON format for easy reloading.\"\"\"\n",
    "    serializable_results = {\n",
    "        json.dumps({\n",
    "            \"Model\": model,\n",
    "            \"Transforms\": transforms,\n",
    "            \"Lags\": list(lags),\n",
    "            \"Lag Transforms\": lag_transforms,\n",
    "            \"Lag Name\": lag_name\n",
    "        }): mape\n",
    "        for (model, transforms, lags, lag_transforms, lag_name), mape in results.items()\n",
    "    }\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(serializable_results, f, indent=4)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "def load_results(filename=\"forecast_results.json\"):\n",
    "    \"\"\"Loads results from JSON and reconstructs into a structured DataFrame.\"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        loaded_results = json.load(f)\n",
    "    \n",
    "    unpacked_results = []\n",
    "    for key, mape_metr in loaded_results.items():\n",
    "        result_data = json.loads(key)  # Convert back from JSON string\n",
    "        \n",
    "        unpacked_results.append([\n",
    "            result_data[\"Model\"],\n",
    "            result_data[\"Transforms\"],\n",
    "            tuple(result_data[\"Lags\"]),  # Convert back to tuple\n",
    "            result_data[\"Lag Transforms\"],\n",
    "            result_data[\"Lag Name\"],\n",
    "            mape_metr\n",
    "        ])\n",
    "    \n",
    "    # Convert into DataFrame\n",
    "    df_results = pd.DataFrame(unpacked_results, columns=[\"Model\", \"Transforms\", \"Lags\", \"Lag Transforms\", \"Lag Name\", \"MAPE\"])\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def rolling_mean_14(x):\n",
    "    return rolling_mean(x, window_size=14)\n",
    "@njit\n",
    "def rolling_mean_30(x):\n",
    "    return rolling_mean(x, window_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    # \"XGBRegressor\": XGBRegressor(),\n",
    "    # \"SGDRegressor\": SGDRegressor(),\n",
    "    # \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso()\n",
    "}\n",
    "\n",
    "# Define lag transformations\n",
    "\n",
    "lag_transforms_options = [\n",
    "    {1: [expanding_mean], 7: [rolling_mean_14], 30: [expanding_mean]},\n",
    "    # {1: [rolling_mean_14], 7: [rolling_mean_30], 30: [expanding_mean]},\n",
    "    # {1: [rolling_mean_14], 30: [expanding_mean]},\n",
    "    # {1: [rolling_mean_14]},\n",
    "    # {},\n",
    "]\n",
    "\n",
    "# Load dataset\n",
    "df = create_dummy_data()\n",
    "df['unique_id'] = 0\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "# Define train and test\n",
    "train_df = df[df[\"ds\"].between(\"2021-01-01\", \"2021-12-31\")]\n",
    "test_df = df[df[\"ds\"].between(\"2022-01-01\", \"2022-12-31\")]\n",
    "\n",
    "# Run evaluation\n",
    "optimal_lags_list = get_optimal_lags(train_df, \"y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model fits to run: 15\n",
      "0/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x0000022958978A10>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 121.52% with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x0000022958978A10>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "1/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoSeasonalDifferences object at 0x0000022959A64DA0>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 702.15% with transforms (<mlforecast.target_transforms.AutoSeasonalDifferences object at 0x0000022959A64DA0>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "2/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoSeasonalityAndDifferences object at 0x0000022959A64680>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 121.52% with transforms (<mlforecast.target_transforms.AutoSeasonalityAndDifferences object at 0x0000022959A64680>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "3/15 Training Lasso with transforms (<mlforecast.target_transforms.LocalStandardScaler object at 0x0000022959A64FE0>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 121.52% with transforms (<mlforecast.target_transforms.LocalStandardScaler object at 0x0000022959A64FE0>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "4/15 Training Lasso with transforms (<mlforecast.target_transforms.LocalMinMaxScaler object at 0x0000022959A64E60>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 121.52% with transforms (<mlforecast.target_transforms.LocalMinMaxScaler object at 0x0000022959A64E60>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "5/15 Training Lasso with transforms (<mlforecast.target_transforms.LocalBoxCox object at 0x0000022959A67530>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Skipping combination due to error: All values in data must be positive for method='loglik'\n",
      "6/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x0000022958978A10>, <mlforecast.target_transforms.LocalStandardScaler object at 0x0000022959A64FE0>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 121.52% with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x0000022958978A10>, <mlforecast.target_transforms.LocalStandardScaler object at 0x0000022959A64FE0>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "7/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x0000022958978A10>, <mlforecast.target_transforms.LocalMinMaxScaler object at 0x0000022959A64E60>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 121.52% with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x0000022958978A10>, <mlforecast.target_transforms.LocalMinMaxScaler object at 0x0000022959A64E60>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "8/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x0000022958978A10>, <mlforecast.target_transforms.LocalBoxCox object at 0x0000022959A67530>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Skipping combination due to error: All values in data must be positive for method='loglik'\n",
      "9/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoSeasonalDifferences object at 0x0000022959A64DA0>, <mlforecast.target_transforms.LocalStandardScaler object at 0x0000022959A64FE0>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 702.15% with transforms (<mlforecast.target_transforms.AutoSeasonalDifferences object at 0x0000022959A64DA0>, <mlforecast.target_transforms.LocalStandardScaler object at 0x0000022959A64FE0>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "10/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoSeasonalDifferences object at 0x0000022959A64DA0>, <mlforecast.target_transforms.LocalMinMaxScaler object at 0x0000022959A64E60>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 702.15% with transforms (<mlforecast.target_transforms.AutoSeasonalDifferences object at 0x0000022959A64DA0>, <mlforecast.target_transforms.LocalMinMaxScaler object at 0x0000022959A64E60>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "11/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoSeasonalDifferences object at 0x0000022959A64DA0>, <mlforecast.target_transforms.LocalBoxCox object at 0x0000022959A67530>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Skipping combination due to error: All values in data must be positive for method='loglik'\n",
      "12/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoSeasonalityAndDifferences object at 0x0000022959A64680>, <mlforecast.target_transforms.LocalStandardScaler object at 0x0000022959A64FE0>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 121.52% with transforms (<mlforecast.target_transforms.AutoSeasonalityAndDifferences object at 0x0000022959A64680>, <mlforecast.target_transforms.LocalStandardScaler object at 0x0000022959A64FE0>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "13/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoSeasonalityAndDifferences object at 0x0000022959A64680>, <mlforecast.target_transforms.LocalMinMaxScaler object at 0x0000022959A64E60>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Lasso MAPE: 121.52% with transforms (<mlforecast.target_transforms.AutoSeasonalityAndDifferences object at 0x0000022959A64680>, <mlforecast.target_transforms.LocalMinMaxScaler object at 0x0000022959A64E60>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n",
      "14/15 Training Lasso with transforms (<mlforecast.target_transforms.AutoSeasonalityAndDifferences object at 0x0000022959A64680>, <mlforecast.target_transforms.LocalBoxCox object at 0x0000022959A67530>), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}...\n",
      "Skipping combination due to error: All values in data must be positive for method='loglik'\n",
      "Best Model: Lasso with MAPE 121.52% using transforms (<mlforecast.target_transforms.LocalStandardScaler object at 0x0000022959A64FE0>,), lags [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45], and lag_transforms {1: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)], 7: [CPUDispatcher(<function rolling_mean_14 at 0x0000022953CB6E80>)], 30: [CPUDispatcher(<function expanding_mean at 0x00000229589740E0>)]}\n"
     ]
    }
   ],
   "source": [
    "target_transforms = get_dynamic_transforms(train_df)\n",
    "results = evaluate_models(train_df, test_df, models, target_transforms, lag_transforms_options, {'lags_45_features_14': [1, 2, 3, 4, 5, 6, 10, 25, 31, 33, 41, 42, 44, 45]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to forecast_results.json\n"
     ]
    }
   ],
   "source": [
    "save_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
