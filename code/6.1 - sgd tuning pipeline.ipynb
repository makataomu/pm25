{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "\n",
    "@njit\n",
    "def rolling_mean_14(x):\n",
    "    return rolling_mean(x, window_size=14)\n",
    "@njit\n",
    "def rolling_mean_30(x):\n",
    "    return rolling_mean(x, window_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_to_mlforecast(df, date_col, target_col, unique_id='mean'):\n",
    "    df_ = df.rename({\n",
    "        date_col: \"ds\",\n",
    "        # target_col: 'y',\n",
    "    }, axis=1)\n",
    "\n",
    "    df_['ds'] = pd.to_datetime(df_['ds'])\n",
    "\n",
    "    df_['y'] = df_[target_col].copy()\n",
    "    # df_.drop(columns=target_col)\n",
    "\n",
    "    df_['unique_id'] = unique_id\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sensors_df = pd.read_csv(\"../data/selected_sensors2_cleaned.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_START_DATE = \"2019-04-02\"\n",
    "scenarios_sensors = {\n",
    "    # 0: 1, 4372603\n",
    "    # \"0_12M_train_7M_test\": {\"train_start\": \"2017-03-25\", \"train_end\": \"2018-03-25\", \"test_start\": \"2018-03-26\", \"test_end\": \"2018-10-10\"},\n",
    "    '2': {\n",
    "        # \"18M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-10-01\"},\n",
    "        \"12M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\", \"val_start\": \"2017-04-01\", \"val_end\": \"2018-04-01\"},\n",
    "        # \"12M_train_3M_val\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\", \"val_start\": \"2018-04-01\", \"val_end\": \"2018-07-01\"},\n",
    "        \"12M_train_6M_val\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\", \"val_start\": \"2018-04-01\", \"val_end\": \"2018-10-01\"},\n",
    "        \"12M_train_9M_val\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\", \"val_start\": \"2018-04-01\", \"val_end\": \"2019-01-01\"},\n",
    "        \"12M_train_12M_val\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\", \"val_start\": \"2018-04-01\", \"val_end\": \"2019-04-01\"},\n",
    "        },\n",
    "}\n",
    "scenarios_sensors['5'] = scenarios_sensors['2'].copy()\n",
    "scenarios_sensors['6'] = scenarios_sensors['2'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from MLForecastPipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_split_data(df, scenario, test_start_date=TEST_START_DATE, date_col=\"ds\"):\n",
    "    \"\"\"Extracts train and test data based on train end date.\"\"\"\n",
    "    train_data = df[df[date_col] <= scenario['train_end']]\n",
    "    val_data = df[(df[date_col] > scenario['val_start']) & (df[date_col] <= scenario['val_end'])]\n",
    "    test_data = df[df[date_col] >= test_start_date]\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "models = {\n",
    "    \"SGD_Ridge\": SGDRegressor( penalty='l2', alpha=1, random_state=42 ),\n",
    "    \"SGDRegressor\": SGDRegressor(random_state=42),\n",
    "    \"SGD_ElasticNet\": SGDRegressor( penalty='elasticnet', l1_ratio=0.5, alpha=0.001, random_state=42 ),\n",
    "}\n",
    "\n",
    "# Define lag transformations\n",
    "from mlforecast.lag_transforms import *\n",
    "lag_transforms_options = [\n",
    "    # {},\n",
    "    {1: [rolling_mean_14], 7: [rolling_mean_30], 30: [expanding_mean]},\n",
    "    {1: [expanding_mean], 7: [rolling_mean_14], 30: [expanding_mean]},\n",
    "    # {7: [RollingMean(window_size=7)], 30: [RollingMean(window_size=30)], 60: [RollingMean(window_size=60)], },\n",
    "    {7: [RollingMean(7), RollingStd(7)], 30: [RollingMean(30)], 60: [ExpandingMean()], 14: [ExponentiallyWeightedMean(alpha=0.3)],},\n",
    "    {7: [RollingMean(7), RollingStd(7), ExpandingStd()], 14: [RollingMean(14), ExpandingStd(), ExponentiallyWeightedMean(alpha=0.3)], 30: [RollingMean(30)], 60: [ExpandingMean()],},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to MLForecast format\n",
    "def format_multi_df_to_mlforecast(df):\n",
    "    df_melted = df.melt(id_vars=['full_date'], var_name='unique_id', value_name='y')\n",
    "    return df_melted.rename(columns={'full_date': 'ds'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_objective(trial, train_df, test_df, transforms, lags, lag_transforms):\n",
    "    alpha = trial.suggest_float('alpha', 1e-6, 1, log=True)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.0, 1.0)\n",
    "    max_iter = trial.suggest_int('max_iter', 300, 1000, step=100)  # Optimizing max_iter (number of iterations)\n",
    "    eta0 = trial.suggest_float('eta0', 1e-6, 1, log=True)\n",
    "\n",
    "    model = SGDRegressor(alpha=alpha, l1_ratio=l1_ratio, max_iter=max_iter, eta0=eta0, penalty='elasticnet', random_state=42)\n",
    "\n",
    "    try:\n",
    "        fcst = MLForecast(\n",
    "            models=[model],\n",
    "            freq='D',\n",
    "            lags=lags,\n",
    "            target_transforms=transforms,\n",
    "            lag_transforms=lag_transforms,\n",
    "            num_threads=1,\n",
    "        )\n",
    "        fcst.fit(train_df)\n",
    "        predictions = fcst.predict(h=len(test_df))\n",
    "        mape = mape_met(test_df['y'].values, predictions['SGDRegressor'].values)\n",
    "        return mape\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return float('inf')\n",
    "    \n",
    "import optuna\n",
    "\n",
    "def run_optuna_search(train_df, test_df, transforms, lags, lag_transforms, n_trials=30):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: optuna_objective(trial, train_df, test_df, transforms, lags, lag_transforms), n_trials=n_trials)\n",
    "    return study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_name = '2'\n",
    "scenario = scenarios_sensors['2']['12M_train']\n",
    "ratios = [1]\n",
    "\n",
    "formatted_df = format_df_to_mlforecast(selected_sensors_df[['full_date', sensor_name]], 'full_date', sensor_name, unique_id=sensor_name)\n",
    "formatted_df = formatted_df[['ds', 'y', 'unique_id']]\n",
    "\n",
    "train_df, val_data, test_df = full_split_data(formatted_df, scenario)\n",
    "optimal_lags_list = get_optimal_lags(train_df, 'y', ratios=ratios)\n",
    "target_transforms = get_dynamic_transforms(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transform_combinations = [()] + list(chain(combinations(target_transforms, 1), combinations(target_transforms, 2)))\n",
    "valid_transform_combinations = [tc for tc in valid_transform_combinations if filter_conflicting_transforms(tc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 14:14:12,345] A new study created in memory with name: no-name-347e80d5-0a21-4d8f-b60c-d045e9c2d995\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\mlforecast\\core.py:626: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-08 14:14:12,692] Trial 0 finished with value: inf and parameters: {'alpha': 0.0008072307404295863, 'l1_ratio': 0.7703668529292352, 'max_iter': 300, 'eta0': 0.006491475892088861}. Best is trial 0 with value: inf.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\mlforecast\\core.py:626: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-08 14:14:12,864] Trial 1 finished with value: inf and parameters: {'alpha': 0.002157657136466659, 'l1_ratio': 0.2739360031073027, 'max_iter': 300, 'eta0': 0.001348077090140433}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\mlforecast\\core.py:626: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-08 14:14:13,009] Trial 2 finished with value: inf and parameters: {'alpha': 1.0901394705055e-05, 'l1_ratio': 0.9514060115642948, 'max_iter': 900, 'eta0': 0.5720848412238454}. Best is trial 0 with value: inf.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-08 14:14:13,162] Trial 3 finished with value: inf and parameters: {'alpha': 3.9875043172176754e-06, 'l1_ratio': 0.22134645946030518, 'max_iter': 1000, 'eta0': 0.13740815840559908}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 14:14:15,166] Trial 4 finished with value: 61.50301833239493 and parameters: {'alpha': 0.0176407181056202, 'l1_ratio': 0.31609865261911774, 'max_iter': 600, 'eta0': 4.8747256239306424e-05}. Best is trial 4 with value: 61.50301833239493.\n",
      "[I 2025-04-08 14:14:16,876] Trial 5 finished with value: 61.817042161136726 and parameters: {'alpha': 0.17046359985186602, 'l1_ratio': 0.18235603891093888, 'max_iter': 500, 'eta0': 2.2833045333422668e-05}. Best is trial 4 with value: 61.50301833239493.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-08 14:14:17,016] Trial 6 finished with value: inf and parameters: {'alpha': 3.646471861245323e-05, 'l1_ratio': 0.8808569558180018, 'max_iter': 1000, 'eta0': 0.001530935285231787}. Best is trial 4 with value: 61.50301833239493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-08 14:14:17,688] Trial 7 finished with value: inf and parameters: {'alpha': 0.015321219204176758, 'l1_ratio': 0.8924273492916988, 'max_iter': 700, 'eta0': 0.00019887728653923242}. Best is trial 4 with value: 61.50301833239493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 14:14:20,223] Trial 8 finished with value: 63.308539897731464 and parameters: {'alpha': 5.810854544258895e-05, 'l1_ratio': 0.03449952744303186, 'max_iter': 1000, 'eta0': 1.852635120534001e-05}. Best is trial 4 with value: 61.50301833239493.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-08 14:14:20,610] Trial 9 finished with value: inf and parameters: {'alpha': 0.0003764347330703556, 'l1_ratio': 0.7851447641042258, 'max_iter': 1000, 'eta0': 0.07171678078101697}. Best is trial 4 with value: 61.50301833239493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[I 2025-04-08 14:14:22,121] Trial 10 finished with value: 77.8790246644507 and parameters: {'alpha': 0.41773586790438727, 'l1_ratio': 0.49766817951795994, 'max_iter': 600, 'eta0': 1.1576791727374017e-06}. Best is trial 4 with value: 61.50301833239493.\n",
      "[I 2025-04-08 14:14:23,735] Trial 11 finished with value: 66.78516135360722 and parameters: {'alpha': 0.37523206791409097, 'l1_ratio': 0.3629930950648338, 'max_iter': 500, 'eta0': 2.4708992352618388e-05}. Best is trial 4 with value: 61.50301833239493.\n",
      "[I 2025-04-08 14:14:25,664] Trial 12 finished with value: 65.97290504655139 and parameters: {'alpha': 0.025717508790257956, 'l1_ratio': 0.03932947801272646, 'max_iter': 500, 'eta0': 2.5078737926980635e-05}. Best is trial 4 with value: 61.50301833239493.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[I 2025-04-08 14:14:26,999] Trial 13 finished with value: 71.21602062699944 and parameters: {'alpha': 0.039941093677072825, 'l1_ratio': 0.5216491753495696, 'max_iter': 700, 'eta0': 2.1981503245204994e-06}. Best is trial 4 with value: 61.50301833239493.\n",
      "[I 2025-04-08 14:14:29,818] Trial 14 finished with value: 18930337.331385415 and parameters: {'alpha': 0.13973677556203348, 'l1_ratio': 0.17687130291832417, 'max_iter': 500, 'eta0': 0.00014424948653303271}. Best is trial 4 with value: 61.50301833239493.\n",
      "[I 2025-04-08 14:14:31,263] Trial 15 finished with value: 56.994915520991306 and parameters: {'alpha': 0.0050929184535476475, 'l1_ratio': 0.4409821352026919, 'max_iter': 800, 'eta0': 7.004535803179687e-06}. Best is trial 15 with value: 56.994915520991306.\n",
      "[I 2025-04-08 14:14:32,862] Trial 16 finished with value: 62.9941898729828 and parameters: {'alpha': 0.004577503587764184, 'l1_ratio': 0.5309092566696423, 'max_iter': 800, 'eta0': 7.5278089818917805e-06}. Best is trial 15 with value: 56.994915520991306.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-08 14:14:33,628] Trial 17 finished with value: inf and parameters: {'alpha': 0.006301754504073421, 'l1_ratio': 0.38875877948354665, 'max_iter': 800, 'eta0': 0.00021815544394286718}. Best is trial 15 with value: 56.994915520991306.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[I 2025-04-08 14:14:35,289] Trial 18 finished with value: 60.711636472966276 and parameters: {'alpha': 0.00048295695945396223, 'l1_ratio': 0.6218526362989849, 'max_iter': 800, 'eta0': 4.754703303962651e-06}. Best is trial 15 with value: 56.994915520991306.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[I 2025-04-08 14:14:36,947] Trial 19 finished with value: 71.94082796084005 and parameters: {'alpha': 0.00019248909158924775, 'l1_ratio': 0.6448490925589914, 'max_iter': 800, 'eta0': 1.8291983257261274e-06}. Best is trial 15 with value: 56.994915520991306.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[I 2025-04-08 14:14:39,606] Trial 20 finished with value: 57.15958018485598 and parameters: {'alpha': 0.00013667308587985092, 'l1_ratio': 0.6275974022773998, 'max_iter': 900, 'eta0': 5.4466010648628235e-06}. Best is trial 15 with value: 56.994915520991306.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[I 2025-04-08 14:14:40,871] Trial 21 finished with value: 56.98368183104551 and parameters: {'alpha': 9.62096805105516e-05, 'l1_ratio': 0.6218804835598938, 'max_iter': 900, 'eta0': 5.504815309340243e-06}. Best is trial 21 with value: 56.98368183104551.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[I 2025-04-08 14:14:43,286] Trial 22 finished with value: 56.60678601035287 and parameters: {'alpha': 1.108314250615282e-06, 'l1_ratio': 0.6583255928274782, 'max_iter': 900, 'eta0': 5.631890695741014e-06}. Best is trial 22 with value: 56.60678601035287.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[I 2025-04-08 14:14:45,218] Trial 23 finished with value: 75.91262211323895 and parameters: {'alpha': 3.0675618927592464e-06, 'l1_ratio': 0.7393451788866566, 'max_iter': 900, 'eta0': 1.04493537270735e-06}. Best is trial 22 with value: 56.60678601035287.\n",
      "[I 2025-04-08 14:14:46,387] Trial 24 finished with value: 88.39686634476702 and parameters: {'alpha': 1.1688516136424252e-06, 'l1_ratio': 0.4414155619419422, 'max_iter': 900, 'eta0': 8.217608234331703e-05}. Best is trial 22 with value: 56.60678601035287.\n",
      "[I 2025-04-08 14:14:48,814] Trial 25 finished with value: 60.16931213241755 and parameters: {'alpha': 2.3785688826045757e-05, 'l1_ratio': 0.6843504398646957, 'max_iter': 700, 'eta0': 9.091395492158067e-06}. Best is trial 22 with value: 56.60678601035287.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-08 14:14:48,971] Trial 26 finished with value: inf and parameters: {'alpha': 0.0017933794768114945, 'l1_ratio': 0.5521892722570063, 'max_iter': 900, 'eta0': 0.0005559844009085617}. Best is trial 22 with value: 56.60678601035287.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\mlforecast\\core.py:626: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-08 14:14:49,132] Trial 27 finished with value: inf and parameters: {'alpha': 1.1291477416409134e-06, 'l1_ratio': 0.44615320110711254, 'max_iter': 800, 'eta0': 0.004818407533541057}. Best is trial 22 with value: 56.60678601035287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[I 2025-04-08 14:14:51,480] Trial 28 finished with value: 60.251390851190564 and parameters: {'alpha': 8.381271616915755e-06, 'l1_ratio': 0.7080252295746956, 'max_iter': 900, 'eta0': 4.482494436410979e-06}. Best is trial 22 with value: 56.60678601035287.\n",
      "c:\\Users\\77019\\pyver\\py312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-08 14:14:51,705] Trial 29 finished with value: inf and parameters: {'alpha': 0.0009132708027707777, 'l1_ratio': 0.7948395281290991, 'max_iter': 700, 'eta0': 0.02735623287979543}. Best is trial 22 with value: 56.60678601035287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    }
   ],
   "source": [
    "transforms = list(valid_transform_combinations[1])\n",
    "lags = optimal_lags_list[list(optimal_lags_list.keys())[0]]\n",
    "lag_transforms = lag_transforms_options[0]\n",
    "\n",
    "best_params = run_optuna_search(train_df, val_data, transforms, lags, lag_transforms, n_trials=30)\n",
    "\n",
    "optuna_model = SGDRegressor(**best_params, random_state=42)\n",
    "models['SGD_Optuna'] = optuna_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "def process_scenario(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options, ratios=[0.33, 0.66, 1]):\n",
    "    \"\"\" Process each scenario independently and save results. \"\"\"\n",
    "    print(f'{sensor_name}_{scenario_name}')\n",
    "    formatted_df = format_df_to_mlforecast(selected_sensors_df[['full_date', sensor_name]], 'full_date', sensor_name, unique_id=sensor_name)\n",
    "    formatted_df = formatted_df[['ds', 'y', 'unique_id']]\n",
    "    \n",
    "    train_df, test_df = split_data(formatted_df, scenario)\n",
    "    optimal_lags_list = get_optimal_lags(train_df, 'y', ratios=ratios)\n",
    "    target_transforms = get_dynamic_transforms(train_df)\n",
    "\n",
    "    results = evaluate_models(train_df, test_df, models, target_transforms, lag_transforms_options, optimal_lags_list)\n",
    "\n",
    "    # Save results\n",
    "    save_results(results, f\"results/run_18/{sensor_name}_{scenario_name}.csv\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def run_all_scenarios_parallel(scenarios_sensors, selected_sensors_df, models, lag_transforms_options, ratios=[0.33, 0.66, 1]):\n",
    "    # don't use all cpus (instead all but one)\n",
    "    results = Parallel(n_jobs=15)( \n",
    "        delayed(process_scenario)(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options, ratios=ratios)\n",
    "        for sensor_name, scenarios in scenarios_sensors.items()\n",
    "        for scenario_name, scenario in scenarios.items()\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
