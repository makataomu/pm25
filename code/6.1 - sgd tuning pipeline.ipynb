{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "\n",
    "@njit\n",
    "def rolling_mean_14(x):\n",
    "    return rolling_mean(x, window_size=14)\n",
    "@njit\n",
    "def rolling_mean_30(x):\n",
    "    return rolling_mean(x, window_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_to_mlforecast(df, date_col, target_col, unique_id='mean'):\n",
    "    df_ = df.rename({\n",
    "        date_col: \"ds\",\n",
    "        # target_col: 'y',\n",
    "    }, axis=1)\n",
    "\n",
    "    df_['ds'] = pd.to_datetime(df_['ds'])\n",
    "\n",
    "    df_['y'] = df_[target_col].copy()\n",
    "    # df_.drop(columns=target_col)\n",
    "\n",
    "    df_['unique_id'] = unique_id\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sensors_df = pd.read_csv(\"../data/selected_sensors2_cleaned.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_START_DATE = \"2019-04-02\"\n",
    "scenarios_sensors = {\n",
    "    # 0: 1, 4372603\n",
    "    # \"0_12M_train_7M_test\": {\"train_start\": \"2017-03-25\", \"train_end\": \"2018-03-25\", \"test_start\": \"2018-03-26\", \"test_end\": \"2018-10-10\"},\n",
    "    '2': {\n",
    "        # \"18M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-10-01\"},\n",
    "        # \"12M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\", \"val_start\": \"2017-04-01\", \"val_end\": \"2018-04-01\"},\n",
    "        # \"12M_train_3M_val\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\", \"val_start\": \"2018-04-01\", \"val_end\": \"2018-07-01\"},\n",
    "        \"12M_train_6M_val\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\", \"val_start\": \"2018-04-01\", \"val_end\": \"2018-10-01\"},\n",
    "        \"12M_train_9M_val\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\", \"val_start\": \"2018-04-01\", \"val_end\": \"2019-01-01\"},\n",
    "        \"12M_train_12M_val\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\", \"val_start\": \"2018-04-01\", \"val_end\": \"2019-04-01\"},\n",
    "        },\n",
    "}\n",
    "scenarios_sensors['5'] = scenarios_sensors['2'].copy()\n",
    "scenarios_sensors['6'] = scenarios_sensors['2'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLForecastPipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_split_data(df, scenario, test_start_date=TEST_START_DATE, date_col=\"ds\"):\n",
    "    train_data = df[df[date_col] <= scenario['train_end']]\n",
    "    val_data = df[(df[date_col] > scenario['val_start']) & (df[date_col] <= scenario['val_end'])]\n",
    "    test_data = df[df[date_col] >= test_start_date]\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def split_data(df, scenario, date_col=\"ds\"):\n",
    "    \"\"\"Extracts train and test data based on train end date.\"\"\"\n",
    "    train_data = df[df[date_col] <= scenario['train_end']]\n",
    "    test_start = pd.to_datetime(scenario['train_end']) + pd.Timedelta(days=1)\n",
    "    test_data = df[df[date_col] >= test_start]\n",
    "    return train_data, test_data\n",
    "\n",
    "models = {\n",
    "    \"SGD_Optuna\": SGDRegressor( penalty='elasticnet', l1_ratio=0.5, alpha=0.001, random_state=42 ),\n",
    "    # \"SGDRegressor\": SGDRegressor(random_state=42),\n",
    "    # \"SGD_ElasticNet\": SGDRegressor( penalty='elasticnet', l1_ratio=0.5, alpha=0.001, random_state=42 ),\n",
    "}\n",
    "\n",
    "# Define lag transformations\n",
    "from mlforecast.lag_transforms import *\n",
    "lag_transforms_options = [\n",
    "    # {},\n",
    "    {1: [rolling_mean_14], 7: [rolling_mean_30], 30: [expanding_mean]},\n",
    "    {1: [expanding_mean], 7: [rolling_mean_14], 30: [expanding_mean]},\n",
    "    # {7: [RollingMean(window_size=7)], 30: [RollingMean(window_size=30)], 60: [RollingMean(window_size=60)], },\n",
    "    {7: [RollingMean(7), RollingStd(7)], 30: [RollingMean(30)], 60: [ExpandingMean()], 14: [ExponentiallyWeightedMean(alpha=0.3)],},\n",
    "    {7: [RollingMean(7), RollingStd(7), ExpandingStd()], 14: [RollingMean(14), ExpandingStd(), ExponentiallyWeightedMean(alpha=0.3)], 30: [RollingMean(30)], 60: [ExpandingMean()],},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to MLForecast format\n",
    "def format_multi_df_to_mlforecast(df):\n",
    "    df_melted = df.melt(id_vars=['full_date'], var_name='unique_id', value_name='y')\n",
    "    return df_melted.rename(columns={'full_date': 'ds'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_objective(trial, train_df, test_df, transforms, lags, lag_transforms):\n",
    "    alpha = trial.suggest_float('alpha', 1e-6, 1, log=True)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.0, 1.0)\n",
    "    max_iter = trial.suggest_int('max_iter', 300, 1000, step=100)  # Optimizing max_iter (number of iterations)\n",
    "    eta0 = trial.suggest_float('eta0', 1e-6, 1, log=True)\n",
    "    tol = trial.suggest_loguniform('tol', 1e-6, 1e-3)\n",
    "\n",
    "    model = SGDRegressor(alpha=alpha, l1_ratio=l1_ratio, max_iter=max_iter, eta0=eta0, tol=tol, penalty='elasticnet', random_state=42)\n",
    "\n",
    "    try:\n",
    "        fcst = MLForecast(\n",
    "            models=[model],\n",
    "            freq='D',\n",
    "            lags=lags,\n",
    "            target_transforms=transforms,\n",
    "            lag_transforms=lag_transforms,\n",
    "            num_threads=1,\n",
    "        )\n",
    "        fcst.fit(train_df)\n",
    "        predictions = fcst.predict(h=len(test_df))\n",
    "        mape = mape_met(test_df['y'].values, predictions['SGDRegressor'].values)\n",
    "        return mape\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return float('inf')\n",
    "    \n",
    "import optuna\n",
    "\n",
    "def run_optuna_search(train_df, test_df, transforms, lags, lag_transforms, n_trials=30):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: optuna_objective(trial, train_df, test_df, transforms, lags, lag_transforms), n_trials=n_trials)\n",
    "    return study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "def process_scenario(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options, ratios=[0.33, 0.66, 1]):\n",
    "    \"\"\" Process each scenario independently and save results. \"\"\"\n",
    "    print(f'{sensor_name}_{scenario_name}')\n",
    "    formatted_df = format_df_to_mlforecast(selected_sensors_df[['full_date', sensor_name]], 'full_date', sensor_name, unique_id=sensor_name)\n",
    "    formatted_df = formatted_df[['ds', 'y', 'unique_id']]\n",
    "    \n",
    "    _, val_test_df = split_data(formatted_df, scenario) # everything after train\n",
    "    train_df, val_df, test_df = full_split_data(formatted_df, scenario) # here different validation set but same test \n",
    "    optimal_lags_list = get_optimal_lags(train_df, 'y', ratios=ratios, low_resources=True)\n",
    "    target_transforms = get_dynamic_transforms(train_df, remove_boxcox=True)\n",
    "\n",
    "    print(len(target_transforms))\n",
    "    print(len(optimal_lags_list))\n",
    "    print(len(models))\n",
    "    print(len(lag_transforms_options))\n",
    "\n",
    "    results = evaluate_models_sgd_tune(train_df, val_df, val_test_df, models, target_transforms, lag_transforms_options, optimal_lags_list, n_jobs=-1, n_trials=30)\n",
    "\n",
    "    # Save results\n",
    "    save_results(results, f\"results/run_18/{sensor_name}_{scenario_name}.csv\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def run_all_scenarios_parallel(scenarios_sensors, selected_sensors_df, models, lag_transforms_options, ratios=[0.33, 0.66, 1]):\n",
    "    # don't use all cpus (instead all but one)\n",
    "    results = Parallel(n_jobs=15)( \n",
    "        delayed(process_scenario)(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options, ratios=ratios)\n",
    "        for sensor_name, scenarios in scenarios_sensors.items()\n",
    "        for scenario_name, scenario in scenarios.items()\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m run_all_scenarios_parallel(scenarios_sensors, selected_sensors_df, models, lag_transforms_options)\n",
      "Cell \u001b[1;32mIn[24], line 29\u001b[0m, in \u001b[0;36mrun_all_scenarios_parallel\u001b[1;34m(scenarios_sensors, selected_sensors_df, models, lag_transforms_options, ratios)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_all_scenarios_parallel\u001b[39m(scenarios_sensors, selected_sensors_df, models, lag_transforms_options, ratios\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.33\u001b[39m, \u001b[38;5;241m0.66\u001b[39m, \u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# don't use all cpus (instead all but one)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)( \n\u001b[0;32m     30\u001b[0m         delayed(process_scenario)(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options, ratios\u001b[38;5;241m=\u001b[39mratios)\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sensor_name, scenarios \u001b[38;5;129;01min\u001b[39;00m scenarios_sensors\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m scenario_name, scenario \u001b[38;5;129;01min\u001b[39;00m scenarios\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     33\u001b[0m     )\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_all_scenarios_parallel(scenarios_sensors, selected_sensors_df, models, lag_transforms_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_12M_train_6M_val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-09 08:59:35,810] A new study created in memory with name: no-name-ed21a705-6f20-4a91-9ce9-87dd5dd59dfc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n",
      "1\n",
      "4\n",
      "Total model fits to run: 4320\n",
      "0/4320 Training SGD_Optuna with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 18, 20, 22, 23, 24, 25, 29, 33, 41, 44, 57, 67, 69, 79, 80, 82, 83, 94, 105, 107, 116, 127, 129, 132, 137, 141, 148, 153, 154, 156, 159, 160, 162, 163, 167, 169, 170, 171, 172, 173, 175, 177, 178, 180, 183, 185, 187, 188], and lag_transforms {1: [<function rolling_mean_14 at 0x000001FD2B418E00>], 7: [<function rolling_mean_30 at 0x000001FD2B44A2A0>], 30: [<function expanding_mean at 0x000001FD24420720>]}...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:37,882] Trial 12 finished with value: inf and parameters: {'alpha': 0.0007315965577640477, 'l1_ratio': 0.587193593523315, 'max_iter': 500, 'eta0': 0.018293531866598486, 'tol': 5.173663090714001e-06}. Best is trial 12 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:38,000] Trial 4 finished with value: inf and parameters: {'alpha': 1.2808852932047719e-05, 'l1_ratio': 0.17107824186526477, 'max_iter': 500, 'eta0': 0.14400738812836636, 'tol': 2.3556080640895496e-06}. Best is trial 12 with value: inf.\n",
      "[I 2025-04-09 08:59:38,071] Trial 1 finished with value: inf and parameters: {'alpha': 1.7131258876784303e-05, 'l1_ratio': 0.34590055762466454, 'max_iter': 800, 'eta0': 0.013436432474878727, 'tol': 2.7788051806742748e-06}. Best is trial 12 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:38,312] Trial 8 finished with value: inf and parameters: {'alpha': 0.0015723009245656421, 'l1_ratio': 0.7494377201743752, 'max_iter': 700, 'eta0': 0.0055666774003914204, 'tol': 1.0730097164261747e-06}. Best is trial 12 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:38,436] Trial 14 finished with value: inf and parameters: {'alpha': 8.623296322048994e-05, 'l1_ratio': 0.30129628648207185, 'max_iter': 500, 'eta0': 0.0018150086980172563, 'tol': 0.0004830936407582558}. Best is trial 12 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:38,499] Trial 11 finished with value: inf and parameters: {'alpha': 0.2970027376756536, 'l1_ratio': 0.9555154589132866, 'max_iter': 600, 'eta0': 0.0024506575665742126, 'tol': 7.211330580674857e-05}. Best is trial 12 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-09 08:59:38,566] Trial 13 finished with value: inf and parameters: {'alpha': 0.0367434717928846, 'l1_ratio': 0.12207342307166946, 'max_iter': 1000, 'eta0': 0.0001343532747390097, 'tol': 5.688496787250103e-06}. Best is trial 12 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:38,877] Trial 2 finished with value: inf and parameters: {'alpha': 0.49898071738855754, 'l1_ratio': 0.8971236510550014, 'max_iter': 500, 'eta0': 0.0008753995533379639, 'tol': 3.710087529628714e-05}. Best is trial 12 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:38,977] Trial 3 finished with value: inf and parameters: {'alpha': 0.0008748330804464631, 'l1_ratio': 0.07379556867714121, 'max_iter': 800, 'eta0': 4.2228231803804616e-05, 'tol': 0.00031280832085448776}. Best is trial 12 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:39,680] Trial 9 finished with value: inf and parameters: {'alpha': 3.676929861760608e-05, 'l1_ratio': 0.30583136923358956, 'max_iter': 600, 'eta0': 2.9671917193053912e-05, 'tol': 2.8309916773651202e-05}. Best is trial 12 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:40,057] Trial 19 finished with value: inf and parameters: {'alpha': 0.06070839509117587, 'l1_ratio': 0.9499064325129335, 'max_iter': 400, 'eta0': 0.13226698409082346, 'tol': 5.4911750921125726e-05}. Best is trial 12 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-09 08:59:40,262] Trial 20 finished with value: inf and parameters: {'alpha': 0.00019176806199351632, 'l1_ratio': 0.09953810996215717, 'max_iter': 800, 'eta0': 0.21189724651702124, 'tol': 0.00034714350044709534}. Best is trial 12 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:40,815] Trial 23 finished with value: inf and parameters: {'alpha': 8.475962680046677e-06, 'l1_ratio': 0.28146793232783973, 'max_iter': 700, 'eta0': 0.1621789307962142, 'tol': 2.192463584207441e-06}. Best is trial 12 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:40,815] Trial 17 finished with value: inf and parameters: {'alpha': 0.00043722798729659853, 'l1_ratio': 0.3585418769885286, 'max_iter': 800, 'eta0': 7.473522985009681e-05, 'tol': 1.075051011382046e-05}. Best is trial 12 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:40,961] Trial 21 finished with value: inf and parameters: {'alpha': 0.13763046429752443, 'l1_ratio': 0.11027113549928902, 'max_iter': 700, 'eta0': 0.00014005594584959625, 'tol': 2.443767161205936e-05}. Best is trial 12 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:41,103] Trial 24 finished with value: inf and parameters: {'alpha': 9.157274751757255e-06, 'l1_ratio': 0.23305450981583342, 'max_iter': 900, 'eta0': 0.0003781554648993383, 'tol': 1.0916216654646895e-06}. Best is trial 12 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:41,293] Trial 25 finished with value: inf and parameters: {'alpha': 2.048133448840346e-06, 'l1_ratio': 0.4943929179376575, 'max_iter': 300, 'eta0': 0.5206412982484182, 'tol': 1.1255299013051219e-05}. Best is trial 12 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:41,884] Trial 26 finished with value: inf and parameters: {'alpha': 1.0792824499645903e-06, 'l1_ratio': 0.5221333959643059, 'max_iter': 900, 'eta0': 0.0003095174176630742, 'tol': 1.5361841089880626e-05}. Best is trial 12 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-09 08:59:46,093] Trial 0 finished with value: 1241.9991377307333 and parameters: {'alpha': 0.020457106827078096, 'l1_ratio': 0.9067103683253428, 'max_iter': 500, 'eta0': 1.0084617517649527e-05, 'tol': 0.00046867513298244065}. Best is trial 0 with value: 1241.9991377307333.\n",
      "[I 2025-04-09 08:59:46,529] Trial 7 finished with value: 909.0615529884456 and parameters: {'alpha': 0.0567352280695525, 'l1_ratio': 0.44102317732997165, 'max_iter': 600, 'eta0': 4.150588638423256e-06, 'tol': 3.084810538264113e-05}. Best is trial 7 with value: 909.0615529884456.\n",
      "[I 2025-04-09 08:59:46,544] Trial 6 finished with value: 929.1350421861166 and parameters: {'alpha': 0.22747333618248183, 'l1_ratio': 0.19425524238902792, 'max_iter': 1000, 'eta0': 2.6257272391932425e-06, 'tol': 3.347181568323112e-05}. Best is trial 7 with value: 909.0615529884456.\n",
      "[I 2025-04-09 08:59:46,564] Trial 10 finished with value: 1.1627206527823348e+160 and parameters: {'alpha': 2.3303701701328635e-05, 'l1_ratio': 0.328518503234555, 'max_iter': 300, 'eta0': 2.541324416604149e-05, 'tol': 5.0448794261770654e-05}. Best is trial 7 with value: 909.0615529884456.\n",
      "[I 2025-04-09 08:59:47,448] Trial 16 finished with value: 1233.8913870133954 and parameters: {'alpha': 0.00018569231974283393, 'l1_ratio': 0.7368225204937193, 'max_iter': 900, 'eta0': 9.281938667190404e-06, 'tol': 0.00013443085105510215}. Best is trial 7 with value: 909.0615529884456.\n",
      "[I 2025-04-09 08:59:47,483] Trial 5 finished with value: 929.4517722622099 and parameters: {'alpha': 0.03222876295861283, 'l1_ratio': 0.21589172822391844, 'max_iter': 300, 'eta0': 2.5535639283270246e-06, 'tol': 0.0001345718858905397}. Best is trial 7 with value: 909.0615529884456.\n",
      "[I 2025-04-09 08:59:47,535] Trial 15 finished with value: 1235.4974498959352 and parameters: {'alpha': 0.03598946611563129, 'l1_ratio': 0.014318598081526024, 'max_iter': 700, 'eta0': 9.419159569164272e-06, 'tol': 8.96729356552046e-06}. Best is trial 7 with value: 909.0615529884456.\n",
      "[I 2025-04-09 08:59:47,600] Trial 27 finished with value: 929.6927688067478 and parameters: {'alpha': 1.2027141080390311e-06, 'l1_ratio': 0.5429586146602119, 'max_iter': 300, 'eta0': 2.8283029264785473e-06, 'tol': 1.653867217343972e-05}. Best is trial 7 with value: 909.0615529884456.\n",
      "[I 2025-04-09 08:59:47,795] Trial 18 finished with value: 874.4210757738961 and parameters: {'alpha': 1.1428170719716845e-06, 'l1_ratio': 0.8724307731715423, 'max_iter': 1000, 'eta0': 1.5770422448649712e-06, 'tol': 1.3771278494102096e-06}. Best is trial 18 with value: 874.4210757738961.\n",
      "[I 2025-04-09 08:59:47,882] Trial 22 finished with value: 1178.3651572531498 and parameters: {'alpha': 3.159512957367645e-05, 'l1_ratio': 0.6111266002423728, 'max_iter': 800, 'eta0': 6.652367004729863e-06, 'tol': 0.0004565313457374996}. Best is trial 18 with value: 874.4210757738961.\n",
      "[I 2025-04-09 08:59:47,886] Trial 28 finished with value: 897.3695819478722 and parameters: {'alpha': 0.012953265673165707, 'l1_ratio': 0.5643415997699508, 'max_iter': 300, 'eta0': 1.7613316270210162e-06, 'tol': 1.9764400079291215e-05}. Best is trial 18 with value: 874.4210757738961.\n",
      "[I 2025-04-09 08:59:47,913] Trial 29 finished with value: 909.4900149007657 and parameters: {'alpha': 1.8732835815539862e-06, 'l1_ratio': 0.5523333075159964, 'max_iter': 300, 'eta0': 4.0778926830734346e-06, 'tol': 2.1345124064004783e-05}. Best is trial 18 with value: 874.4210757738961.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:48,031] A new study created in memory with name: no-name-1819b390-8941-4027-90e4-beadcd36ec7e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping combination 0 due to error: Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "1/4320 Training SGD_Optuna with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 18, 20, 22, 23, 24, 25, 29, 33, 41, 44, 57, 67, 69, 79, 80, 82, 83, 94, 105, 107, 116, 127, 129, 132, 137, 141, 148, 153, 154, 156, 159, 160, 162, 163, 167, 169, 170, 171, 172, 173, 175, 177, 178, 180, 183, 185, 187, 188], and lag_transforms {1: [<function expanding_mean at 0x000001FD24420720>], 7: [<function rolling_mean_14 at 0x000001FD2B418E00>], 30: [<function expanding_mean at 0x000001FD24420720>]}...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:49,493] Trial 0 finished with value: inf and parameters: {'alpha': 7.822331259034175e-05, 'l1_ratio': 0.3751600815493432, 'max_iter': 400, 'eta0': 0.05412829441759753, 'tol': 3.882545720742197e-05}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, expanding_mean_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:49,976] Trial 7 finished with value: inf and parameters: {'alpha': 8.874046948928672e-05, 'l1_ratio': 0.21605984842935466, 'max_iter': 300, 'eta0': 0.034371966009138714, 'tol': 1.3221552389324548e-06}. Best is trial 0 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:50,067] Trial 15 finished with value: inf and parameters: {'alpha': 0.0003057221289059529, 'l1_ratio': 0.4866446760113323, 'max_iter': 500, 'eta0': 0.34061206894843693, 'tol': 4.57555836710961e-05}. Best is trial 0 with value: inf.\n",
      "[I 2025-04-09 08:59:50,114] Trial 10 finished with value: inf and parameters: {'alpha': 0.5000683030721292, 'l1_ratio': 0.5166520230558908, 'max_iter': 800, 'eta0': 0.06031169446466656, 'tol': 5.686715634379314e-06}. Best is trial 0 with value: inf.\n",
      "[I 2025-04-09 08:59:50,114] Trial 9 finished with value: inf and parameters: {'alpha': 0.602250917768648, 'l1_ratio': 0.4151352017537492, 'max_iter': 600, 'eta0': 0.16686748554842373, 'tol': 0.00020627640507901707}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, expanding_mean_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:50,315] Trial 6 finished with value: inf and parameters: {'alpha': 0.28604923649646913, 'l1_ratio': 0.8113522809992693, 'max_iter': 1000, 'eta0': 0.0010096950115891822, 'tol': 2.6678654888154823e-06}. Best is trial 0 with value: inf.\n",
      "[I 2025-04-09 08:59:50,327] Trial 5 finished with value: inf and parameters: {'alpha': 0.2079247526430561, 'l1_ratio': 0.2807526684952347, 'max_iter': 900, 'eta0': 0.004587743266474825, 'tol': 0.00019122015936777004}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, expanding_mean_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:50,530] Trial 8 finished with value: inf and parameters: {'alpha': 0.00023580524866251564, 'l1_ratio': 0.2899150139214327, 'max_iter': 400, 'eta0': 0.00848803699624195, 'tol': 6.4313357013501824e-06}. Best is trial 0 with value: inf.\n",
      "[I 2025-04-09 08:59:50,582] Trial 11 finished with value: inf and parameters: {'alpha': 0.0001859175125703487, 'l1_ratio': 0.327060275173215, 'max_iter': 700, 'eta0': 0.003747993308312507, 'tol': 1.0918717838360486e-05}. Best is trial 0 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:50,619] Trial 1 finished with value: inf and parameters: {'alpha': 0.7767376483130534, 'l1_ratio': 0.05684441229067605, 'max_iter': 800, 'eta0': 0.0006486071014065759, 'tol': 0.0007984668938390536}. Best is trial 0 with value: inf.\n",
      "[I 2025-04-09 08:59:50,645] Trial 2 finished with value: inf and parameters: {'alpha': 0.0007589377219071038, 'l1_ratio': 0.5684279769385705, 'max_iter': 1000, 'eta0': 0.0059090420640588205, 'tol': 0.0003713675779164333}. Best is trial 0 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, expanding_mean_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-09 08:59:50,736] Trial 12 finished with value: inf and parameters: {'alpha': 4.4250717193340596e-05, 'l1_ratio': 0.09208637085127935, 'max_iter': 400, 'eta0': 0.0028214177975646906, 'tol': 0.00044659650682767353}. Best is trial 0 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, expanding_mean_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:51,244] Trial 14 finished with value: inf and parameters: {'alpha': 1.613944286633586e-05, 'l1_ratio': 0.8404925363826703, 'max_iter': 900, 'eta0': 7.106480740154533e-05, 'tol': 2.596376465667074e-06}. Best is trial 0 with value: inf.\n",
      "[I 2025-04-09 08:59:51,260] Trial 13 finished with value: inf and parameters: {'alpha': 1.2928191913391338e-06, 'l1_ratio': 0.24913726877172349, 'max_iter': 600, 'eta0': 9.815720075504627e-05, 'tol': 1.0437716825666892e-05}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:52,049] Trial 20 finished with value: inf and parameters: {'alpha': 4.6252361869036605e-06, 'l1_ratio': 0.3958741707716128, 'max_iter': 800, 'eta0': 0.048329839520807, 'tol': 0.0005658951312201785}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, expanding_mean_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n",
      "[I 2025-04-09 08:59:52,350] Trial 21 finished with value: inf and parameters: {'alpha': 0.00269999477593708, 'l1_ratio': 0.37986572715303335, 'max_iter': 600, 'eta0': 0.0037878302552657368, 'tol': 0.0009259014730316143}. Best is trial 0 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:52,497] Trial 17 finished with value: inf and parameters: {'alpha': 9.000551450082623e-06, 'l1_ratio': 0.18365567483971768, 'max_iter': 500, 'eta0': 0.016020594173524964, 'tol': 1.8129435514914112e-05}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:52,649] Trial 18 finished with value: inf and parameters: {'alpha': 0.017547463921571436, 'l1_ratio': 0.16648058199282545, 'max_iter': 300, 'eta0': 7.859227453996728e-05, 'tol': 2.482965795297158e-06}. Best is trial 0 with value: inf.\n",
      "[I 2025-04-09 08:59:52,734] Trial 19 finished with value: inf and parameters: {'alpha': 0.037208490713357335, 'l1_ratio': 0.09767828570923831, 'max_iter': 300, 'eta0': 0.000230634494590802, 'tol': 0.00029309082877319577}. Best is trial 0 with value: inf.\n",
      "[I 2025-04-09 08:59:52,734] Trial 16 finished with value: inf and parameters: {'alpha': 0.00014450538521013564, 'l1_ratio': 0.8163156657247347, 'max_iter': 300, 'eta0': 3.477569284225496e-05, 'tol': 2.117782775148816e-05}. Best is trial 0 with value: inf.\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:52,915] Trial 23 finished with value: inf and parameters: {'alpha': 0.5028823614421953, 'l1_ratio': 0.9391375928632983, 'max_iter': 500, 'eta0': 9.106765803600684e-05, 'tol': 0.00029833013994362323}. Best is trial 0 with value: inf.\n",
      "[I 2025-04-09 08:59:52,984] Trial 24 finished with value: inf and parameters: {'alpha': 0.07498997489432147, 'l1_ratio': 0.6474980957265364, 'max_iter': 500, 'eta0': 0.00010116035583803932, 'tol': 7.348284750199721e-05}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n",
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "[I 2025-04-09 08:59:54,963] Trial 25 finished with value: inf and parameters: {'alpha': 2.8076525280989703e-06, 'l1_ratio': 0.006301223376877246, 'max_iter': 700, 'eta0': 2.846187512602953e-05, 'tol': 5.220398504011821e-05}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-09 08:59:56,394] Trial 3 finished with value: 906.5438091881477 and parameters: {'alpha': 0.0007665875136460211, 'l1_ratio': 0.298088906058554, 'max_iter': 300, 'eta0': 2.8483582134075847e-06, 'tol': 0.00047735338094288967}. Best is trial 3 with value: 906.5438091881477.\n",
      "[I 2025-04-09 08:59:56,580] Trial 4 finished with value: 1165.6515220209108 and parameters: {'alpha': 5.941145027993189e-05, 'l1_ratio': 0.533145097608076, 'max_iter': 400, 'eta0': 1.0953066748900995e-06, 'tol': 1.2844817827753353e-05}. Best is trial 3 with value: 906.5438091881477.\n",
      "[I 2025-04-09 08:59:56,697] Trial 22 finished with value: 861.0545277761358 and parameters: {'alpha': 4.143779642168948e-06, 'l1_ratio': 0.6585917012615998, 'max_iter': 1000, 'eta0': 1.6046116066323753e-06, 'tol': 3.053507216546032e-06}. Best is trial 22 with value: 861.0545277761358.\n",
      "[I 2025-04-09 08:59:56,795] Trial 28 finished with value: 884.3018207464805 and parameters: {'alpha': 0.01313731156098636, 'l1_ratio': 0.052572803711477815, 'max_iter': 700, 'eta0': 4.203190767240965e-06, 'tol': 0.000984714253358916}. Best is trial 22 with value: 861.0545277761358.\n",
      "[I 2025-04-09 08:59:56,892] Trial 29 finished with value: 1083.8675617512338 and parameters: {'alpha': 0.008204503486037365, 'l1_ratio': 0.03913541003691012, 'max_iter': 700, 'eta0': 5.348998336693176e-06, 'tol': 5.046100831366308e-05}. Best is trial 22 with value: 861.0545277761358.\n",
      "[I 2025-04-09 08:59:57,079] Trial 27 finished with value: 5.039183254389461e+277 and parameters: {'alpha': 1.769133108135323e-06, 'l1_ratio': 0.10307431624393629, 'max_iter': 700, 'eta0': 2.6760731919887353e-05, 'tol': 3.929129578497393e-05}. Best is trial 22 with value: 861.0545277761358.\n",
      "[I 2025-04-09 08:59:57,079] Trial 26 finished with value: 9755.285895595365 and parameters: {'alpha': 0.012696355160051019, 'l1_ratio': 0.011860350679710537, 'max_iter': 700, 'eta0': 2.036678670808027e-05, 'tol': 5.0736992076667795e-05}. Best is trial 22 with value: 861.0545277761358.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sensor_name, scenarios \u001b[38;5;129;01min\u001b[39;00m scenarios_sensors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m scenario_name, scenario \u001b[38;5;129;01min\u001b[39;00m scenarios\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 3\u001b[0m         process_scenario(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options)\n",
      "Cell \u001b[1;32mIn[24], line 20\u001b[0m, in \u001b[0;36mprocess_scenario\u001b[1;34m(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options, ratios)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(models))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lag_transforms_options))\n\u001b[1;32m---> 20\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluate_models_sgd_tune(train_df, val_df, val_test_df, models, target_transforms, lag_transforms_options, optimal_lags_list, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m     23\u001b[0m save_results(results, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/run_18/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msensor_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscenario_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\Documents\\tair\\pm25\\code\\MLForecastPipeline.py:514\u001b[0m, in \u001b[0;36mevaluate_models_sgd_tune\u001b[1;34m(train_df, val_df, val_test_df, models, target_transforms, lag_transforms_options, optimal_lags_list, date_features, n_trials, n_jobs)\u001b[0m\n\u001b[0;32m    502\u001b[0m fcst \u001b[38;5;241m=\u001b[39m MLForecast(\n\u001b[0;32m    503\u001b[0m     models\u001b[38;5;241m=\u001b[39m[model],\n\u001b[0;32m    504\u001b[0m     freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m     lag_transforms\u001b[38;5;241m=\u001b[39mlag_transforms,\n\u001b[0;32m    510\u001b[0m )\n\u001b[0;32m    512\u001b[0m fcst\u001b[38;5;241m.\u001b[39mfit(train_df)\n\u001b[1;32m--> 514\u001b[0m predictions \u001b[38;5;241m=\u001b[39m fcst\u001b[38;5;241m.\u001b[39mpredict(h\u001b[38;5;241m=\u001b[39mmax_test_length)\n\u001b[0;32m    515\u001b[0m test_df_copy \u001b[38;5;241m=\u001b[39m val_test_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    516\u001b[0m test_df_copy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforecast\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions[get_sgdreg_name(model_name)]\u001b[38;5;241m.\u001b[39mvalues       \n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\forecast.py:738\u001b[0m, in \u001b[0;36mMLForecast.predict\u001b[1;34m(self, h, before_predict_callback, after_predict_callback, new_df, level, X_df, ids)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    736\u001b[0m     ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mts\n\u001b[1;32m--> 738\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    739\u001b[0m     models\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_,\n\u001b[0;32m    740\u001b[0m     horizon\u001b[38;5;241m=\u001b[39mh,\n\u001b[0;32m    741\u001b[0m     before_predict_callback\u001b[38;5;241m=\u001b[39mbefore_predict_callback,\n\u001b[0;32m    742\u001b[0m     after_predict_callback\u001b[38;5;241m=\u001b[39mafter_predict_callback,\n\u001b[0;32m    743\u001b[0m     X_df\u001b[38;5;241m=\u001b[39mX_df,\n\u001b[0;32m    744\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    745\u001b[0m )\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cs_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:825\u001b[0m, in \u001b[0;36mTimeSeries.predict\u001b[1;34m(self, models, horizon, before_predict_callback, after_predict_callback, X_df, ids)\u001b[0m\n\u001b[0;32m    823\u001b[0m     X_df \u001b[38;5;241m=\u001b[39m ufp\u001b[38;5;241m.\u001b[39mdrop_columns(X_df, drop_cols)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_horizon\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_recursive(\n\u001b[0;32m    826\u001b[0m         models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[0;32m    827\u001b[0m         horizon\u001b[38;5;241m=\u001b[39mhorizon,\n\u001b[0;32m    828\u001b[0m         before_predict_callback\u001b[38;5;241m=\u001b[39mbefore_predict_callback,\n\u001b[0;32m    829\u001b[0m         after_predict_callback\u001b[38;5;241m=\u001b[39mafter_predict_callback,\n\u001b[0;32m    830\u001b[0m         X_df\u001b[38;5;241m=\u001b[39mX_df,\n\u001b[0;32m    831\u001b[0m     )\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_multi(\n\u001b[0;32m    834\u001b[0m         models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[0;32m    835\u001b[0m         horizon\u001b[38;5;241m=\u001b[39mhorizon,\n\u001b[0;32m    836\u001b[0m         before_predict_callback\u001b[38;5;241m=\u001b[39mbefore_predict_callback,\n\u001b[0;32m    837\u001b[0m         X_df\u001b[38;5;241m=\u001b[39mX_df,\n\u001b[0;32m    838\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:670\u001b[0m, in \u001b[0;36mTimeSeries._predict_recursive\u001b[1;34m(self, models, horizon, before_predict_callback, after_predict_callback, X_df)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m before_predict_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    669\u001b[0m     new_x \u001b[38;5;241m=\u001b[39m before_predict_callback(new_x)\n\u001b[1;32m--> 670\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(new_x)\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m after_predict_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    672\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m after_predict_callback(predictions)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1691\u001b[0m, in \u001b[0;36mBaseSGDRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the linear model.\u001b[39;00m\n\u001b[0;32m   1680\u001b[0m \n\u001b[0;32m   1681\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;124;03m       Predicted target values per element in X.\u001b[39;00m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decision_function(X)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1673\u001b[0m, in \u001b[0;36mBaseSGDRegressor._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the linear model\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m \n\u001b[0;32m   1662\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1669\u001b[0m \u001b[38;5;124;03m   Predicted target values per element in X.\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1671\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1673\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\u001b[38;5;28mself\u001b[39m, X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1675\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:920\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_sparse\u001b[39m(dtype):\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, SparseDtype)\n\u001b[1;32m--> 920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mapply(is_sparse)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    921\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    922\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame with sparse columns found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    923\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt will be converted to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    924\u001b[0m         )\n\u001b[0;32m    926\u001b[0m dtypes_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtypes)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6461\u001b[0m, in \u001b[0;36mNDFrame.dtypes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6434\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6435\u001b[0m \u001b[38;5;124;03mReturn the dtypes in the DataFrame.\u001b[39;00m\n\u001b[0;32m   6436\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6458\u001b[0m \u001b[38;5;124;03mdtype: object\u001b[39;00m\n\u001b[0;32m   6459\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6460\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mget_dtypes()\n\u001b[1;32m-> 6461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(data, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:593\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    590\u001b[0m         data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n\u001b[0;32m    592\u001b[0m NDFrame\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data)\n\u001b[1;32m--> 593\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_axis(\u001b[38;5;241m0\u001b[39m, index)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_pandas_object \u001b[38;5;129;01mand\u001b[39;00m data_dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6320\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6317\u001b[0m \u001b[38;5;66;03m# if this fails, go on to more involved attribute setting\u001b[39;00m\n\u001b[0;32m   6318\u001b[0m \u001b[38;5;66;03m# (note that this matches __getattr__, above).\u001b[39;00m\n\u001b[0;32m   6319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set:\n\u001b[1;32m-> 6320\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[0;32m   6321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata:\n\u001b[0;32m   6322\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:786\u001b[0m, in \u001b[0;36mSeries.name\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;129m@name\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 786\u001b[0m     validate_all_hashable(value, error_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, value)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\common.py:1590\u001b[0m, in \u001b[0;36mvalidate_all_hashable\u001b[1;34m(error_name, *args)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_all_hashable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, error_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;124;03m    Return None if all args are hashable, else raise a TypeError.\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1588\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_hashable(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m   1591\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m error_name:\n\u001b[0;32m   1592\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be a hashable type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\common.py:1590\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_all_hashable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, error_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;124;03m    Return None if all args are hashable, else raise a TypeError.\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1588\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_hashable(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m   1591\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m error_name:\n\u001b[0;32m   1592\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be a hashable type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\inference.py:334\u001b[0m, in \u001b[0;36mis_hashable\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m    Check if the object is a named tuple.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, abc\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_hashable\u001b[39m(obj) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TypeGuard[Hashable]:\n\u001b[0;32m    335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    Return True if hash(obj) will succeed, False otherwise.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# Unfortunately, we can't use isinstance(obj, collections.abc.Hashable),\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# which can be faster than calling hash. That is because numpy scalars\u001b[39;00m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;66;03m# fail this test.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Reconsider this decision once this numpy bug is fixed:\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# https://github.com/numpy/numpy/issues/5562\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for sensor_name, scenarios in scenarios_sensors.items():\n",
    "    for scenario_name, scenario in scenarios.items():\n",
    "        process_scenario(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
