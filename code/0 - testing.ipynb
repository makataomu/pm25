{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLForecastPipeline import *\n",
    "\n",
    "def split_data(df, scenario, date_col=\"ds\"):\n",
    "    \"\"\"Extracts train and test data based on train end date.\"\"\"\n",
    "    train_data = df[df[date_col] <= scenario['train_end']]\n",
    "    test_start = pd.to_datetime(scenario['train_end']) + pd.Timedelta(days=1)\n",
    "    test_data = df[df[date_col] >= test_start]\n",
    "    return train_data, test_data\n",
    "\n",
    "selected_sensors_df = pd.read_csv(\"../data/selected_sensors2_cleaned.csv\", index_col=0)\n",
    "testing_df = format_df_to_mlforecast(selected_sensors_df, 'full_date', '2')[['ds', 'y', 'unique_id']]\n",
    "testing_df['ds'] = pd.to_datetime(testing_df['ds'])\n",
    "train_df, test_df = split_data(testing_df, {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ds",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "unique_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0159d910-70f9-40a9-96f3-878832e6c77a",
       "rows": [
        [
         "0",
         "2017-03-22 00:00:00",
         "40.683844011142064",
         "mean"
        ],
        [
         "1",
         "2017-03-23 00:00:00",
         "29.237465181058496",
         "mean"
        ],
        [
         "2",
         "2017-03-24 00:00:00",
         "43.675636363636364",
         "mean"
        ],
        [
         "3",
         "2017-03-25 00:00:00",
         "58.79221681723419",
         "mean"
        ],
        [
         "4",
         "2017-03-26 00:00:00",
         "48.34840055632824",
         "mean"
        ],
        [
         "5",
         "2017-03-27 00:00:00",
         "25.86610878661088",
         "mean"
        ],
        [
         "6",
         "2017-03-28 00:00:00",
         "23.530967292971468",
         "mean"
        ],
        [
         "7",
         "2017-03-29 00:00:00",
         "31.14435879467414",
         "mean"
        ],
        [
         "8",
         "2017-03-30 00:00:00",
         "29.700139470013948",
         "mean"
        ],
        [
         "9",
         "2017-03-31 00:00:00",
         "30.5427974947808",
         "mean"
        ],
        [
         "10",
         "2017-04-01 00:00:00",
         "23.582302568981923",
         "mean"
        ],
        [
         "11",
         "2017-04-02 00:00:00",
         "37.50071022727273",
         "mean"
        ],
        [
         "12",
         "2017-04-03 00:00:00",
         "32.33508956796628",
         "mean"
        ],
        [
         "13",
         "2017-04-04 00:00:00",
         "44.31082118188795",
         "mean"
        ],
        [
         "14",
         "2017-04-05 00:00:00",
         "55.17132867132867",
         "mean"
        ],
        [
         "15",
         "2017-04-06 00:00:00",
         "51.85161744022504",
         "mean"
        ],
        [
         "16",
         "2017-04-07 00:00:00",
         "36.998046875",
         "mean"
        ],
        [
         "17",
         "2017-04-08 00:00:00",
         "44.327856025039125",
         "mean"
        ],
        [
         "18",
         "2017-04-09 00:00:00",
         "49.2080723729993",
         "mean"
        ],
        [
         "19",
         "2017-04-10 00:00:00",
         "49.50386507378777",
         "mean"
        ],
        [
         "20",
         "2017-04-11 00:00:00",
         "22.058950395398995",
         "mean"
        ],
        [
         "21",
         "2017-04-12 00:00:00",
         "8.032235459004905",
         "mean"
        ],
        [
         "22",
         "2017-04-13 00:00:00",
         "12.694226657163222",
         "mean"
        ],
        [
         "23",
         "2017-04-14 00:00:00",
         "18.97103548153512",
         "mean"
        ],
        [
         "24",
         "2017-04-15 00:00:00",
         "34.03138075313807",
         "mean"
        ],
        [
         "25",
         "2017-04-16 00:00:00",
         "44.59357541899441",
         "mean"
        ],
        [
         "26",
         "2017-04-17 00:00:00",
         "19.8845050215208",
         "mean"
        ],
        [
         "27",
         "2017-04-18 00:00:00",
         "31.38434414668547",
         "mean"
        ],
        [
         "28",
         "2017-04-19 00:00:00",
         "37.45705521472393",
         "mean"
        ],
        [
         "29",
         "2017-04-20 00:00:00",
         "22.19706498951782",
         "mean"
        ],
        [
         "30",
         "2017-04-21 00:00:00",
         "19.06633733239238",
         "mean"
        ],
        [
         "31",
         "2017-04-22 00:00:00",
         "17.776462395543174",
         "mean"
        ],
        [
         "32",
         "2017-04-23 00:00:00",
         "19.914804469273744",
         "mean"
        ],
        [
         "33",
         "2017-04-24 00:00:00",
         "19.3562412342216",
         "mean"
        ],
        [
         "34",
         "2017-04-25 00:00:00",
         "19.16890459363957",
         "mean"
        ],
        [
         "35",
         "2017-04-26 00:00:00",
         "19.68975265017668",
         "mean"
        ],
        [
         "36",
         "2017-04-27 00:00:00",
         "9.913616398243043",
         "mean"
        ],
        [
         "37",
         "2017-04-28 00:00:00",
         "8.162952646239555",
         "mean"
        ],
        [
         "38",
         "2017-04-29 00:00:00",
         "18.62831241283124",
         "mean"
        ],
        [
         "39",
         "2017-04-30 00:00:00",
         "19.75091041514931",
         "mean"
        ],
        [
         "40",
         "2017-05-01 00:00:00",
         "13.228890439637125",
         "mean"
        ],
        [
         "41",
         "2017-05-02 00:00:00",
         "29.64772727272728",
         "mean"
        ],
        [
         "42",
         "2017-05-03 00:00:00",
         "19.522585128561506",
         "mean"
        ],
        [
         "43",
         "2017-05-04 00:00:00",
         "27.33727399165508",
         "mean"
        ],
        [
         "44",
         "2017-05-05 00:00:00",
         "15.11482254697286",
         "mean"
        ],
        [
         "45",
         "2017-05-06 00:00:00",
         "17.878745644599302",
         "mean"
        ],
        [
         "46",
         "2017-05-07 00:00:00",
         "16.82033426183844",
         "mean"
        ],
        [
         "47",
         "2017-05-08 00:00:00",
         "23.80362116991644",
         "mean"
        ],
        [
         "48",
         "2017-05-09 00:00:00",
         "15.596100278551532",
         "mean"
        ],
        [
         "49",
         "2017-05-10 00:00:00",
         "12.974198047419804",
         "mean"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 376
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-22</td>\n",
       "      <td>40.683844</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-23</td>\n",
       "      <td>29.237465</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-24</td>\n",
       "      <td>43.675636</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>58.792217</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>48.348401</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>26.094187</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>23.352381</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>23.960317</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>31.329379</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>47.998990</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds          y unique_id\n",
       "0   2017-03-22  40.683844      mean\n",
       "1   2017-03-23  29.237465      mean\n",
       "2   2017-03-24  43.675636      mean\n",
       "3   2017-03-25  58.792217      mean\n",
       "4   2017-03-26  48.348401      mean\n",
       "..         ...        ...       ...\n",
       "371 2018-03-28  26.094187      mean\n",
       "372 2018-03-29  23.352381      mean\n",
       "373 2018-03-30  23.960317      mean\n",
       "374 2018-03-31  31.329379      mean\n",
       "375 2018-04-01  47.998990      mean\n",
       "\n",
       "[376 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "lags must be positive integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 42\u001b[0m\n\u001b[0;32m     37\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProphet\u001b[39m\u001b[38;5;124m\"\u001b[39m: ProphetWrapper()\n\u001b[0;32m     39\u001b[0m }\n\u001b[0;32m     40\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProphet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 42\u001b[0m fcst \u001b[38;5;241m=\u001b[39m MLForecast(\n\u001b[0;32m     43\u001b[0m     models\u001b[38;5;241m=\u001b[39m[models[model_name]],\n\u001b[0;32m     44\u001b[0m     freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     45\u001b[0m     lags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# target_transforms=list(transform_combination),\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# date_features=date_features,\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# lag_transforms=lag_transforms,\u001b[39;00m\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m     53\u001b[0m fcst\u001b[38;5;241m.\u001b[39mfit(train_df)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\forecast.py:167\u001b[0m, in \u001b[0;36mMLForecast.__init__\u001b[1;34m(self, models, freq, lags, lag_transforms, date_features, num_threads, target_transforms, lag_transforms_namer)\u001b[0m\n\u001b[0;32m    165\u001b[0m     models_with_names \u001b[38;5;241m=\u001b[39m models\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels \u001b[38;5;241m=\u001b[39m models_with_names\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mts \u001b[38;5;241m=\u001b[39m TimeSeries(\n\u001b[0;32m    168\u001b[0m     freq\u001b[38;5;241m=\u001b[39mfreq,\n\u001b[0;32m    169\u001b[0m     lags\u001b[38;5;241m=\u001b[39mlags,\n\u001b[0;32m    170\u001b[0m     lag_transforms\u001b[38;5;241m=\u001b[39mlag_transforms,\n\u001b[0;32m    171\u001b[0m     date_features\u001b[38;5;241m=\u001b[39mdate_features,\n\u001b[0;32m    172\u001b[0m     num_threads\u001b[38;5;241m=\u001b[39mnum_threads,\n\u001b[0;32m    173\u001b[0m     target_transforms\u001b[38;5;241m=\u001b[39mtarget_transforms,\n\u001b[0;32m    174\u001b[0m     lag_transforms_namer\u001b[38;5;241m=\u001b[39mlag_transforms_namer,\n\u001b[0;32m    175\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:190\u001b[0m, in \u001b[0;36mTimeSeries.__init__\u001b[1;34m(self, freq, lags, lag_transforms, date_features, num_threads, target_transforms, lag_transforms_namer)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlags:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lag \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lag, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m--> 190\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlags must be positive integers.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlag_transforms \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m lag_transforms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lag_transforms\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlag_transforms\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;31mValueError\u001b[0m: lags must be positive integers."
     ]
    }
   ],
   "source": [
    "\n",
    "from prophet import Prophet\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class ProphetWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, **prophet_params):\n",
    "        self.prophet_params = prophet_params\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Prophet requires a DataFrame with 'ds' and 'y' columns\n",
    "        print(X)\n",
    "        df = X.copy()\n",
    "        df['y'] = y\n",
    "        self.model = Prophet(**self.prophet_params)\n",
    "        self.model.fit(df)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Prophet requires a DataFrame with 'ds' column for predictions\n",
    "        print(\"HEYYYYYYYY - \\n\", X)\n",
    "        future = X[['ds']].copy()\n",
    "        forecast = self.model.predict(future)\n",
    "\n",
    "        # future = self.model.make_future_dataframe(periods=len(X), freq='D')\n",
    "        # forecast = self.model.predict(future)\n",
    "\n",
    "        return forecast['yhat'].values\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.prophet_params\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "models = {\n",
    "    \"Prophet\": ProphetWrapper()\n",
    "}\n",
    "model_name = 'Prophet'\n",
    "\n",
    "fcst = MLForecast(\n",
    "    models=[models[model_name]],\n",
    "    freq='D',\n",
    "    lags=[0],\n",
    "    # target_transforms=list(transform_combination),\n",
    "    # date_features=date_features,\n",
    "    num_threads=1,\n",
    "    # lag_transforms=lag_transforms,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "fcst.fit(train_df)\n",
    "\n",
    "# Predict\n",
    "predictions = fcst.predict(h=test_df.shape[0])\n",
    "test_df_copy = test_df.copy()\n",
    "test_df_copy['forecast'] = predictions[model_name].values     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\77019\\Downloads\\waqi-covid19-airqualitydata-2025.csv\"\n",
    "\n",
    "# Read CSV while skipping comment lines\n",
    "data = pd.read_csv(file_path, comment='#')\n",
    "data = data.loc[data['City'] == \"Almaty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dew', 'co', 'humidity', 'so2', 'pressure', 'wind-speed',\n",
       "       'wind-gust', 'temperature', 'pm10', 'pm25', 'no2'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Specie'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2024-01-01', '2025-03-05')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'].min(), data['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2015H1...\n",
      "✅ waqi-airquality-2015H1.csv downloaded successfully!\n",
      "Downloading 2016H1...\n",
      "✅ waqi-airquality-2016H1.csv downloaded successfully!\n",
      "Downloading 2017H1...\n",
      "✅ waqi-airquality-2017H1.csv downloaded successfully!\n",
      "Downloading 2018H1...\n",
      "✅ waqi-airquality-2018H1.csv downloaded successfully!\n",
      "Downloading 2019Q1...\n",
      "✅ waqi-airquality-2019Q1.csv downloaded successfully!\n",
      "Downloading 2019Q2...\n",
      "✅ waqi-airquality-2019Q2.csv downloaded successfully!\n",
      "Downloading 2019Q3...\n",
      "✅ waqi-airquality-2019Q3.csv downloaded successfully!\n",
      "Downloading 2019Q4...\n",
      "✅ waqi-airquality-2019Q4.csv downloaded successfully!\n",
      "Downloading 2020Q1...\n",
      "✅ waqi-airquality-2020Q1.csv downloaded successfully!\n",
      "Downloading 2020Q2...\n",
      "✅ waqi-airquality-2020Q2.csv downloaded successfully!\n",
      "Downloading 2020Q3...\n",
      "✅ waqi-airquality-2020Q3.csv downloaded successfully!\n",
      "Downloading 2020Q4...\n",
      "✅ waqi-airquality-2020Q4.csv downloaded successfully!\n",
      "Downloading 2021Q1...\n",
      "✅ waqi-airquality-2021Q1.csv downloaded successfully!\n",
      "Downloading 2021Q2...\n",
      "✅ waqi-airquality-2021Q2.csv downloaded successfully!\n",
      "Downloading 2021Q3...\n",
      "✅ waqi-airquality-2021Q3.csv downloaded successfully!\n",
      "Downloading 2021Q4...\n",
      "✅ waqi-airquality-2021Q4.csv downloaded successfully!\n",
      "Downloading 2022Q1...\n",
      "✅ waqi-airquality-2022Q1.csv downloaded successfully!\n",
      "Downloading 2022Q2...\n",
      "✅ waqi-airquality-2022Q2.csv downloaded successfully!\n",
      "Downloading 2022Q3...\n",
      "✅ waqi-airquality-2022Q3.csv downloaded successfully!\n",
      "Downloading 2022Q4...\n",
      "✅ waqi-airquality-2022Q4.csv downloaded successfully!\n",
      "Downloading 2023Q1...\n",
      "✅ waqi-airquality-2023Q1.csv downloaded successfully!\n",
      "Downloading 2023Q2...\n",
      "✅ waqi-airquality-2023Q2.csv downloaded successfully!\n",
      "Downloading 2023Q3...\n",
      "✅ waqi-airquality-2023Q3.csv downloaded successfully!\n",
      "Downloading 2023Q4...\n",
      "✅ waqi-airquality-2023Q4.csv downloaded successfully!\n",
      "🎉 All available datasets have been processed.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# List of available periods\n",
    "periods = [\n",
    "    \"2015H1\", \"2016H1\", \"2017H1\", \"2018H1\",\n",
    "    \"2019Q1\", \"2019Q2\", \"2019Q3\", \"2019Q4\",\n",
    "    \"2020Q1\", \"2020Q2\", \"2020Q3\", \"2020Q4\",\n",
    "    \"2021Q1\", \"2021Q2\", \"2021Q3\", \"2021Q4\",\n",
    "    \"2022Q1\", \"2022Q2\", \"2022Q3\", \"2022Q4\",\n",
    "    \"2023Q1\", \"2023Q2\", \"2023Q3\", \"2023Q4\"\n",
    "]\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://aqicn.org/data-platform/covid19/report/45268-77d0de2d\"\n",
    "\n",
    "# Loop through each period and download the file\n",
    "for period in periods:\n",
    "    url = f\"{base_url}/{period}\"\n",
    "    file_name = f\"waqi-airquality-{period}.csv\"\n",
    "\n",
    "    print(f\"Downloading {period}...\")\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(file_name, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"✅ {file_name} downloaded successfully!\")\n",
    "    else:\n",
    "        print(f\"❌ Failed to download {period}. Status code: {response.status_code}\")\n",
    "\n",
    "    # Add a small delay to prevent overwhelming the server\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"🎉 All available datasets have been processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
