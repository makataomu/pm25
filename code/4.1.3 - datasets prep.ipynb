{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "\n",
    "@njit\n",
    "def rolling_mean_14(x):\n",
    "    return rolling_mean(x, window_size=14)\n",
    "@njit\n",
    "def rolling_mean_30(x):\n",
    "    return rolling_mean(x, window_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_to_mlforecast(df, date_col, target_col, unique_id='mean'):\n",
    "    df_ = df.rename({\n",
    "        date_col: \"ds\",\n",
    "        # target_col: 'y',\n",
    "    }, axis=1)\n",
    "\n",
    "    df_['ds'] = pd.to_datetime(df_['ds'])\n",
    "\n",
    "    df_['y'] = df_[target_col].copy()\n",
    "    # df_.drop(columns=target_col)\n",
    "\n",
    "    df_['unique_id'] = unique_id\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sensors_df = pd.read_csv(\"../data/selected_sensors2_cleaned.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_sensors = {\n",
    "    # 0: 1, 4372603\n",
    "    # \"0_12M_train_7M_test\": {\"train_start\": \"2017-03-25\", \"train_end\": \"2018-03-25\", \"test_start\": \"2018-03-26\", \"test_end\": \"2018-10-10\"},\n",
    "    '2': {\n",
    "        \"26M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2019-06-01\"},\n",
    "        \"24M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2019-04-01\"},\n",
    "        \"22M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2019-02-01\"},\n",
    "        \"20M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-12-01\"},\n",
    "        \"18M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-10-01\"},\n",
    "        \"12M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-04-01\"},\n",
    "        \"10M_train\":  {\"train_start\": \"2017-04-01\", \"train_end\": \"2018-01-25\"},\n",
    "        \"8M_train\":   {\"train_start\": \"2017-04-01\", \"train_end\": \"2017-10-25\"},\n",
    "        },\n",
    "}\n",
    "scenarios_sensors['5'] = scenarios_sensors['2'].copy()\n",
    "scenarios_sensors['6'] = scenarios_sensors['2'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLForecastPipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, scenario, date_col=\"ds\"):\n",
    "    \"\"\"Extracts train and test data based on train end date.\"\"\"\n",
    "    train_data = df[df[date_col] <= scenario['train_end']]\n",
    "    test_start = pd.to_datetime(scenario['train_end']) + pd.Timedelta(days=1)\n",
    "    test_data = df[df[date_col] >= test_start]\n",
    "    return train_data, test_data\n",
    "\n",
    "models = {\n",
    "    \"SGD_Ridge\": SGDRegressor( penalty='l2', alpha=1, random_state=42 ),\n",
    "    \"SGDRegressor\": SGDRegressor(random_state=42),\n",
    "    \"SGD_ElasticNet\": SGDRegressor( penalty='elasticnet', l1_ratio=0.5, alpha=0.001, random_state=42 ),\n",
    "}\n",
    "\n",
    "# Define lag transformations\n",
    "from mlforecast.lag_transforms import *\n",
    "lag_transforms_options = [\n",
    "    {},\n",
    "    {7: [RollingMean(window_size=7)], 30: [RollingMean(window_size=30)], 60: [RollingMean(window_size=60)], },\n",
    "    {7: [RollingMean(7), RollingStd(7)], 30: [RollingMean(30)], 60: [ExpandingMean()], 14: [ExponentiallyWeightedMean(alpha=0.3)],},\n",
    "    {7: [RollingMean(7), RollingStd(7), ExpandingStd()], 14: [RollingMean(14), ExpandingStd(), ExponentiallyWeightedMean(alpha=0.3)], 30: [RollingMean(30)], 60: [ExpandingMean()],},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "def process_scenario(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options, ratios=[0.33, 0.66, 1]):\n",
    "    \"\"\" Process each scenario independently and save results. \"\"\"\n",
    "    print(f'{sensor_name}_{scenario_name}')\n",
    "    formatted_df = format_df_to_mlforecast(selected_sensors_df[['full_date', sensor_name]], 'full_date', sensor_name, unique_id=sensor_name)\n",
    "    formatted_df = formatted_df[['ds', 'y', 'unique_id']]\n",
    "    \n",
    "    train_df, test_df = split_data(formatted_df, scenario)\n",
    "    optimal_lags_list = get_optimal_lags(train_df, 'y', ratios=ratios)\n",
    "    target_transforms = get_dynamic_transforms(train_df)\n",
    "\n",
    "    results = evaluate_models(train_df, test_df, models, target_transforms, lag_transforms_options, optimal_lags_list)\n",
    "\n",
    "    # Save results\n",
    "    save_results(results, f\"results/run_16/{sensor_name}_{scenario_name}.csv\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def run_all_scenarios_parallel(scenarios_sensors, selected_sensors_df, models, lag_transforms_options, ratios=[0.33, 0.66, 1]):\n",
    "    # don't use all cpus (instead all but one)\n",
    "    results = Parallel(n_jobs=15)( \n",
    "        delayed(process_scenario)(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options, ratios=ratios)\n",
    "        for sensor_name, scenarios in scenarios_sensors.items()\n",
    "        for scenario_name, scenario in scenarios.items()\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m run_all_scenarios_parallel(scenarios_sensors, selected_sensors_df, models, lag_transforms_options)\n",
      "Cell \u001b[1;32mIn[17], line 23\u001b[0m, in \u001b[0;36mrun_all_scenarios_parallel\u001b[1;34m(scenarios_sensors, selected_sensors_df, models, lag_transforms_options, ratios)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_all_scenarios_parallel\u001b[39m(scenarios_sensors, selected_sensors_df, models, lag_transforms_options, ratios\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.33\u001b[39m, \u001b[38;5;241m0.66\u001b[39m, \u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# don't use all cpus (instead all but one)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)( \n\u001b[0;32m     24\u001b[0m         delayed(process_scenario)(sensor_name, scenario_name, scenario, selected_sensors_df, models, lag_transforms_options, ratios\u001b[38;5;241m=\u001b[39mratios)\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sensor_name, scenarios \u001b[38;5;129;01min\u001b[39;00m scenarios_sensors\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m scenario_name, scenario \u001b[38;5;129;01min\u001b[39;00m scenarios\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     27\u001b[0m     )\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = run_all_scenarios_parallel(scenarios_sensors, selected_sensors_df, models, lag_transforms_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model fits to run: 1152\n",
      "0/1152 Training XGBRegressor with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n",
      "XGBRegressor MAPE: 41.45% with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}\n",
      "1/1152 Training SGDRegressor_42 with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n",
      "Skipping combination 1 due to error: Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2/1152 Training Ridge with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, expanding_mean_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge MAPE: 63.23% with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}\n",
      "3/1152 Training Lasso with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n",
      "Lasso MAPE: 42.30% with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}\n",
      "4/1152 Training XGBRegressor with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function rolling_mean_14 at 0x00000255838B0AE0>], 7: [<function rolling_mean_30 at 0x00000255838B0FE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n",
      "XGBRegressor MAPE: 40.37% with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function rolling_mean_14 at 0x00000255838B0AE0>], 7: [<function rolling_mean_30 at 0x00000255838B0FE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}\n",
      "5/1152 Training SGDRegressor_42 with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function rolling_mean_14 at 0x00000255838B0AE0>], 7: [<function rolling_mean_30 at 0x00000255838B0FE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n",
      "Skipping combination 5 due to error: Input X contains NaN.\n",
      "SGDRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "6/1152 Training Ridge with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function rolling_mean_14 at 0x00000255838B0AE0>], 7: [<function rolling_mean_30 at 0x00000255838B0FE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:625: UserWarning: Found null values in lag1, rolling_mean_14_lag1.\n",
      "  warnings.warn(f'Found null values in {\", \".join(cols_with_nulls)}.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge MAPE: 49.97% with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function rolling_mean_14 at 0x00000255838B0AE0>], 7: [<function rolling_mean_30 at 0x00000255838B0FE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}\n",
      "7/1152 Training Lasso with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function rolling_mean_14 at 0x00000255838B0AE0>], 7: [<function rolling_mean_30 at 0x00000255838B0FE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n",
      "Lasso MAPE: 42.06% with transforms (), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function rolling_mean_14 at 0x00000255838B0AE0>], 7: [<function rolling_mean_30 at 0x00000255838B0FE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}\n",
      "8/1152 Training XGBRegressor with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x00000255F9608830>,), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n",
      "XGBRegressor MAPE: 58.04% with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x00000255F9608830>,), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}\n",
      "9/1152 Training SGDRegressor_42 with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x00000255F9608830>,), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n",
      "Skipping combination 9 due to error: Input X contains infinity or a value too large for dtype('float64').\n",
      "10/1152 Training Ridge with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x00000255F9608830>,), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge MAPE: 68.08% with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x00000255F9608830>,), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}\n",
      "11/1152 Training Lasso with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x00000255F9608830>,), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n",
      "Lasso MAPE: 49.63% with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x00000255F9608830>,), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function expanding_mean at 0x00000255F6108720>], 7: [<function rolling_mean_14 at 0x00000255838B0AE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}\n",
      "12/1152 Training XGBRegressor with transforms (<mlforecast.target_transforms.AutoDifferences object at 0x00000255F9608830>,), lags [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 18, 27, 36, 37, 41, 43, 48, 54, 63, 64, 73, 74, 77, 78, 79, 80, 81, 97, 98], and lag_transforms {1: [<function rolling_mean_14 at 0x00000255838B0AE0>], 7: [<function rolling_mean_30 at 0x00000255838B0FE0>], 30: [<function expanding_mean at 0x00000255F6108720>]}...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 18\u001b[0m\n\u001b[0;32m     12\u001b[0m optimal_lags_list \u001b[38;5;241m=\u001b[39m get_optimal_lags(train_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     13\u001b[0m                                     \u001b[38;5;66;03m# ratios=[1]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m                                     ratios\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.33\u001b[39m, \u001b[38;5;241m0.66\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     15\u001b[0m                                     \u001b[38;5;66;03m#  ratios=[0.25, 0.5, 0.75, 1]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m target_transforms \u001b[38;5;241m=\u001b[39m get_dynamic_transforms(train_df)\n\u001b[1;32m---> 18\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluate_models(train_df, test_df, models, target_transforms, lag_transforms_options, optimal_lags_list)\n\u001b[0;32m     20\u001b[0m save_results(results, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/run_3/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msensor_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscenario_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\Documents\\tair\\pm25\\code\\MLForecastPipeline.py:235\u001b[0m, in \u001b[0;36mevaluate_models\u001b[1;34m(train_df, test_df, models, target_transforms, lag_transforms_options, optimal_lags_list, date_features)\u001b[0m\n\u001b[0;32m    232\u001b[0m fcst\u001b[38;5;241m.\u001b[39mfit(train_df)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m predictions \u001b[38;5;241m=\u001b[39m fcst\u001b[38;5;241m.\u001b[39mpredict(h\u001b[38;5;241m=\u001b[39mmax_test_length)\n\u001b[0;32m    236\u001b[0m test_df_copy \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    237\u001b[0m test_df_copy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforecast\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions[model_name]\u001b[38;5;241m.\u001b[39mvalues       \n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\forecast.py:738\u001b[0m, in \u001b[0;36mMLForecast.predict\u001b[1;34m(self, h, before_predict_callback, after_predict_callback, new_df, level, X_df, ids)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    736\u001b[0m     ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mts\n\u001b[1;32m--> 738\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    739\u001b[0m     models\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_,\n\u001b[0;32m    740\u001b[0m     horizon\u001b[38;5;241m=\u001b[39mh,\n\u001b[0;32m    741\u001b[0m     before_predict_callback\u001b[38;5;241m=\u001b[39mbefore_predict_callback,\n\u001b[0;32m    742\u001b[0m     after_predict_callback\u001b[38;5;241m=\u001b[39mafter_predict_callback,\n\u001b[0;32m    743\u001b[0m     X_df\u001b[38;5;241m=\u001b[39mX_df,\n\u001b[0;32m    744\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    745\u001b[0m )\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cs_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:825\u001b[0m, in \u001b[0;36mTimeSeries.predict\u001b[1;34m(self, models, horizon, before_predict_callback, after_predict_callback, X_df, ids)\u001b[0m\n\u001b[0;32m    823\u001b[0m     X_df \u001b[38;5;241m=\u001b[39m ufp\u001b[38;5;241m.\u001b[39mdrop_columns(X_df, drop_cols)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_horizon\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_recursive(\n\u001b[0;32m    826\u001b[0m         models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[0;32m    827\u001b[0m         horizon\u001b[38;5;241m=\u001b[39mhorizon,\n\u001b[0;32m    828\u001b[0m         before_predict_callback\u001b[38;5;241m=\u001b[39mbefore_predict_callback,\n\u001b[0;32m    829\u001b[0m         after_predict_callback\u001b[38;5;241m=\u001b[39mafter_predict_callback,\n\u001b[0;32m    830\u001b[0m         X_df\u001b[38;5;241m=\u001b[39mX_df,\n\u001b[0;32m    831\u001b[0m     )\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_multi(\n\u001b[0;32m    834\u001b[0m         models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[0;32m    835\u001b[0m         horizon\u001b[38;5;241m=\u001b[39mhorizon,\n\u001b[0;32m    836\u001b[0m         before_predict_callback\u001b[38;5;241m=\u001b[39mbefore_predict_callback,\n\u001b[0;32m    837\u001b[0m         X_df\u001b[38;5;241m=\u001b[39mX_df,\n\u001b[0;32m    838\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\mlforecast\\core.py:670\u001b[0m, in \u001b[0;36mTimeSeries._predict_recursive\u001b[1;34m(self, models, horizon, before_predict_callback, after_predict_callback, X_df)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m before_predict_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    669\u001b[0m     new_x \u001b[38;5;241m=\u001b[39m before_predict_callback(new_x)\n\u001b[1;32m--> 670\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(new_x)\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m after_predict_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    672\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m after_predict_callback(predictions)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1187\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1188\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1189\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1190\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1191\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1192\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1193\u001b[0m         )\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2508\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2506\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[1;32m-> 2508\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[0;32m   2510\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(fns)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\xgboost\\data.py:611\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[1;34m(data, enable_categorical, feature_names, feature_types, meta)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot have multiple columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    607\u001b[0m feature_names, feature_types \u001b[38;5;241m=\u001b[39m pandas_feature_info(\n\u001b[0;32m    608\u001b[0m     data, meta, feature_names, feature_types, enable_categorical\n\u001b[0;32m    609\u001b[0m )\n\u001b[1;32m--> 611\u001b[0m arrays \u001b[38;5;241m=\u001b[39m pandas_transform_data(data)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PandasTransformed(arrays), feature_names, feature_types\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\xgboost\\data.py:550\u001b[0m, in \u001b[0;36mpandas_transform_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    548\u001b[0m         result\u001b[38;5;241m.\u001b[39mappend(arr)\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 550\u001b[0m         result\u001b[38;5;241m.\u001b[39mappend(oth_type(data[col]))\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# FIXME(jiamingy): Investigate the possibility of using dataframe protocol or arrow\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;66;03m# IPC format for pandas so that we can apply the data transformation inside XGBoost\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# for better memory efficiency.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4078\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4071\u001b[0m \u001b[38;5;66;03m# GH#45316 Return view if key is not duplicated\u001b[39;00m\n\u001b[0;32m   4072\u001b[0m \u001b[38;5;66;03m# Only use drop_duplicates with duplicates for performance\u001b[39;00m\n\u001b[0;32m   4073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   4074\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[0;32m   4075\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4076\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop_duplicates(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   4077\u001b[0m ):\n\u001b[1;32m-> 4078\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(key)\n\u001b[0;32m   4080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m   4081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4639\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4635\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[0;32m   4638\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(item)\n\u001b[1;32m-> 4639\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4641\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   4643\u001b[0m     \u001b[38;5;66;03m# for a chain\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4010\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[1;34m(self, i, axis)\u001b[0m\n\u001b[0;32m   4006\u001b[0m \u001b[38;5;66;03m# icol\u001b[39;00m\n\u001b[0;32m   4007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4008\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[i]\n\u001b[1;32m-> 4010\u001b[0m     col_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39miget(i)\n\u001b[0;32m   4011\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_col_values(col_mgr, i)\n\u001b[0;32m   4013\u001b[0m     \u001b[38;5;66;03m# this is a cached value, mark it so\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC314\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1012\u001b[0m, in \u001b[0;36mBlockManager.iget\u001b[1;34m(self, i, track_ref)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     block \u001b[38;5;241m=\u001b[39m new_block(result, placement\u001b[38;5;241m=\u001b[39mbp, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SingleBlockManager(block, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 1012\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miget\u001b[39m(\u001b[38;5;28mself\u001b[39m, i: \u001b[38;5;28mint\u001b[39m, track_ref: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SingleBlockManager:\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;124;03m    Return the data as a SingleBlockManager.\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos[i]]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop through scenarios and evaluate models\n",
    "results = []\n",
    "\n",
    "for sensor_name, scenarios in scenarios_sensors.items():\n",
    "    formatted_df = format_df_to_mlforecast(selected_sensors_df[['full_date', sensor_name]], 'full_date', sensor_name, unique_id=sensor_name)\n",
    "    formatted_df = formatted_df[['ds', 'y', 'unique_id']]\n",
    "\n",
    "    for scenario_name, scenario in scenarios.items():\n",
    "\n",
    "        train_df, test_df = split_data(formatted_df, scenario)\n",
    "\n",
    "        optimal_lags_list = get_optimal_lags(train_df, 'y', \n",
    "                                            # ratios=[1]\n",
    "                                            ratios=[0.33, 0.66, 1]\n",
    "                                            #  ratios=[0.25, 0.5, 0.75, 1]\n",
    "        )\n",
    "        target_transforms = get_dynamic_transforms(train_df)\n",
    "        results = evaluate_models(train_df, test_df, models, target_transforms, lag_transforms_options, optimal_lags_list)\n",
    "\n",
    "        save_results(results, f\"results/run_6/{sensor_name}_{scenario_name}.csv\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
